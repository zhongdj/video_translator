"""
ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†ç”¨ä¾‹ - ä¿®å¤å­—å¹•é€»è¾‘ç‰ˆæœ¬

å…³é”®ä¿®å¤ï¼š
1. âœ… å­—å¹•å‘½åæ¸…æ™°ï¼šoriginal/target/secondary
2. âœ… TTS ä½¿ç”¨ç›®æ ‡è¯­è¨€ï¼ˆä¸­æ–‡ï¼‰å­—å¹•
3. âœ… åŒè¯­å­—å¹•é¡ºåºæ­£ç¡®ï¼ˆä¸­æ–‡åœ¨ä¸Šï¼Œè‹±æ–‡åœ¨ä¸‹ï¼‰
4. âœ… å®Œæ•´çš„å¯¼å…¥å’Œè¾…åŠ©å‡½æ•°
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Callable
from datetime import datetime

from domain.entities import (
    Video, Subtitle, AudioTrack, ProcessedVideo,
    LanguageCode, AudioSample, TextSegment, TimeRange, VoiceProfile
)
from domain.ports import (
    ASRProvider, TranslationProvider, TTSProvider,
    VideoProcessor, SubtitleWriter, CacheRepository,
)
from domain.services import (
    merge_bilingual_subtitles,
    calculate_cache_key,
)


# ============== ä¸­é—´æ•°æ®ç»“æ„ ============== #

@dataclass(frozen=True)
class VideoWithSubtitles:
    """
    è§†é¢‘ + å­—å¹•çš„ä¸­é—´ç»“æœ

    å­—å¹•å‘½åè§„èŒƒï¼š
    - original_subtitle: ASRè¯†åˆ«çš„åŸå§‹è¯­è¨€å­—å¹•
    - target_subtitle: ç›®æ ‡è¯­è¨€å­—å¹•ï¼ˆä¸­æ–‡ï¼‰
    - secondary_subtitle: æ¬¡è¦è¯­è¨€å­—å¹•ï¼ˆè‹±æ–‡ï¼‰
    """
    video: Video
    original_subtitle: Subtitle      # åŸå§‹è¯†åˆ«è¯­è¨€ï¼ˆzh/en/pt/jaç­‰ï¼‰
    target_subtitle: Subtitle        # ç›®æ ‡è¯­è¨€ï¼ˆä¸­æ–‡ï¼‰
    secondary_subtitle: Subtitle     # æ¬¡è¦è¯­è¨€ï¼ˆè‹±æ–‡ï¼‰
    detected_language: LanguageCode
    cache_hit_subtitle: bool


@dataclass(frozen=True)
class VideoWithAudio:
    """è§†é¢‘ + å­—å¹• + éŸ³é¢‘çš„ä¸­é—´ç»“æœ"""
    video: Video
    original_subtitle: Subtitle
    target_subtitle: Subtitle        # ä¸­æ–‡å­—å¹•
    secondary_subtitle: Subtitle     # è‹±æ–‡å­—å¹•
    detected_language: LanguageCode
    audio_track: Optional[AudioTrack]
    cache_hit_audio: bool


# ============== å­—å¹•ç¼“å­˜è¾…åŠ©å‡½æ•° ============== #

def _load_subtitle_segments(
        cached_data: dict,
        language: LanguageCode,
        segment_key: str
) -> tuple[TextSegment, ...]:
    """ä»ç¼“å­˜åŠ è½½æŒ‡å®šè¯­è¨€çš„å­—å¹•ç‰‡æ®µ"""
    segments_data = cached_data.get(segment_key, [])
    if not segments_data:
        return tuple()

    return tuple(
        TextSegment(
            text=seg["text"],
            time_range=TimeRange(seg["start"], seg["end"]),
            language=language
        )
        for seg in segments_data
    )


def _reconstruct_subtitles_from_cache(
        cached: dict,
        detected_lang: LanguageCode
) -> tuple[Subtitle, Subtitle, Subtitle]:
    """
    ä»ç¼“å­˜é‡å»ºæ‰€æœ‰å­—å¹•

    Returns:
        (original_subtitle, target_subtitle, secondary_subtitle)
    """
    # 1. æ¢å¤ä¸­æ–‡å­—å¹•ï¼ˆç›®æ ‡è¯­è¨€ï¼‰
    zh_segments = _load_subtitle_segments(cached, LanguageCode.CHINESE, "zh_segments")
    target_subtitle = Subtitle(zh_segments, LanguageCode.CHINESE)

    # 2. æ¢å¤è‹±æ–‡å­—å¹•ï¼ˆæ¬¡è¦è¯­è¨€ï¼‰
    en_segments = _load_subtitle_segments(cached, LanguageCode.ENGLISH, "en_segments")
    secondary_subtitle = Subtitle(en_segments, LanguageCode.ENGLISH)

    # 3. æ¢å¤åŸå§‹è¯­è¨€å­—å¹•
    if detected_lang == LanguageCode.CHINESE:
        original_subtitle = target_subtitle
    elif detected_lang == LanguageCode.ENGLISH:
        original_subtitle = secondary_subtitle
    else:
        original_segments = _load_subtitle_segments(
            cached,
            detected_lang,
            f"{detected_lang.value}_segments"
        )
        if original_segments:
            original_subtitle = Subtitle(original_segments, detected_lang)
        else:
            original_subtitle = target_subtitle

    return original_subtitle, target_subtitle, secondary_subtitle


def _serialize_segments(segments: tuple[TextSegment, ...]) -> list:
    """åºåˆ—åŒ–æ–‡æœ¬ç‰‡æ®µä¸ºå­—å…¸åˆ—è¡¨"""
    return [
        {
            "text": seg.text,
            "start": seg.time_range.start_seconds,
            "end": seg.time_range.end_seconds
        }
        for seg in segments
    ]


# ============== å­—å¹•ç¿»è¯‘ç­–ç•¥å‡½æ•° ============== #

def _translate_subtitles(
        original_segments: tuple[TextSegment, ...],
        detected_lang: LanguageCode,
        translation_provider: TranslationProvider
) -> tuple[Subtitle, Subtitle]:
    """
    ç¿»è¯‘å­—å¹•ï¼Œå§‹ç»ˆè¿”å›ä¸­æ–‡å­—å¹•å’Œè‹±æ–‡å­—å¹•

    Returns:
        (target_subtitle: ä¸­æ–‡, secondary_subtitle: è‹±æ–‡)
    """
    if detected_lang == LanguageCode.CHINESE:
        zh_segments = original_segments
        en_segments = translation_provider.translate(
            original_segments,
            LanguageCode.CHINESE,
            LanguageCode.ENGLISH
        )

    elif detected_lang == LanguageCode.ENGLISH:
        en_segments = original_segments
        zh_segments = translation_provider.translate(
            original_segments,
            LanguageCode.ENGLISH,
            LanguageCode.CHINESE
        )

    else:
        en_segments = translation_provider.translate(
            original_segments,
            detected_lang,
            LanguageCode.ENGLISH
        )
        zh_segments = translation_provider.translate(
            en_segments,
            LanguageCode.ENGLISH,
            LanguageCode.CHINESE
        )

    target_subtitle = Subtitle(zh_segments, LanguageCode.CHINESE)
    secondary_subtitle = Subtitle(en_segments, LanguageCode.ENGLISH)

    return target_subtitle, secondary_subtitle


# ============== éŸ³é¢‘å¤„ç†è¾…åŠ©å‡½æ•° ============== #

def _load_audio_from_cache(
        cache_repo: CacheRepository,
        cache_key: str,
        video_name: str,
        language: LanguageCode
) -> Optional[AudioTrack]:
    """ä»ç¼“å­˜åŠ è½½éŸ³é¢‘è½¨é“"""
    try:
        cached = cache_repo.get(cache_key)
        if cached is None:
            return None

        # ä¼˜å…ˆä»éŸ³é¢‘æ–‡ä»¶åŠ è½½
        if "audio_file" in cached:
            audio_file = Path(cached["audio_file"])
            if audio_file.exists():
                try:
                    import numpy as np
                    import soundfile as sf

                    audio_data, sample_rate = sf.read(str(audio_file))
                    audio_sample = AudioSample(
                        samples=tuple(audio_data.tolist()),
                        sample_rate=sample_rate
                    )
                    audio_track = AudioTrack(audio_sample, language)
                    print(f"  ğŸ’¾ éŸ³é¢‘ç¼“å­˜å‘½ä¸­ï¼ˆæ–‡ä»¶ï¼‰: {video_name}")
                    return audio_track
                except Exception as e:
                    print(f"  âš ï¸  éŸ³é¢‘æ–‡ä»¶åŠ è½½å¤±è´¥: {e}")
                    return None

        # å…¼å®¹æ—§æ ¼å¼ï¼šä»å†…å­˜åŠ è½½
        if "audio_samples" in cached and "sample_rate" in cached:
            audio_sample = AudioSample(
                samples=tuple(cached["audio_samples"]),
                sample_rate=cached["sample_rate"]
            )
            audio_track = AudioTrack(audio_sample, language)
            print(f"  ğŸ’¾ éŸ³é¢‘ç¼“å­˜å‘½ä¸­ï¼ˆå†…å­˜ï¼‰: {video_name}")
            return audio_track

        return None

    except (KeyError, TypeError) as e:
        print(f"  âš ï¸  éŸ³é¢‘ç¼“å­˜è§£æå¤±è´¥: {e}")
        return None


def _assemble_full_audio(
        synthesized_audios: tuple,
        segments: tuple[TextSegment, ...],
        video_duration: float,
        language: LanguageCode
) -> AudioTrack:
    """å°†æ‰¹é‡åˆæˆçš„éŸ³é¢‘ç‰‡æ®µæ‹¼æ¥æˆå®Œæ•´éŸ³é¢‘"""
    sample_rate = synthesized_audios[0].sample_rate
    total_samples = int(video_duration * sample_rate)
    full_audio_list = [0.0] * total_samples

    for audio_sample, segment in zip(synthesized_audios, segments):
        start_idx = int(segment.time_range.start_seconds * sample_rate)
        for i, sample in enumerate(audio_sample.samples):
            target_idx = start_idx + i
            if target_idx < total_samples:
                full_audio_list[target_idx] = sample

    full_audio = AudioSample(
        samples=tuple(full_audio_list),
        sample_rate=sample_rate
    )

    return AudioTrack(full_audio, language)


def _save_audio_to_cache(
        cache_repo: CacheRepository,
        cache_key: str,
        audio_track: AudioTrack,
        reference_audio_path: Path,
        video_path: Path
) -> None:
    """ä¿å­˜éŸ³é¢‘åˆ°ç¼“å­˜ï¼ˆæ–‡ä»¶å­˜å‚¨ï¼‰"""
    cache_dir = video_path.parent / ".audio_cache"
    cache_dir.mkdir(exist_ok=True)

    audio_cache_path = cache_dir / f"audio_{cache_key[:16]}.wav"

    try:
        import numpy as np
        import soundfile as sf

        audio_data = np.array(audio_track.audio.samples, dtype=np.float32)
        sf.write(str(audio_cache_path), audio_data, audio_track.audio.sample_rate)

        cache_data = {
            "audio_file": str(audio_cache_path),
            "sample_rate": audio_track.audio.sample_rate,
            "language": audio_track.language.value,
            "reference_audio": str(reference_audio_path),
            "reference_duration": 10.0
        }

        cache_repo.set(cache_key, cache_data)
        print(f"  ğŸ’¾ éŸ³é¢‘å·²ä¿å­˜åˆ°æ–‡ä»¶: {audio_cache_path.name}")

    except Exception as e:
        print(f"  âš ï¸  éŸ³é¢‘ç¼“å­˜ä¿å­˜å¤±è´¥: {e}")
        cache_data = {
            "audio_samples": list(audio_track.audio.samples),
            "sample_rate": audio_track.audio.sample_rate,
            "language": audio_track.language.value,
            "reference_audio": str(reference_audio_path),
            "reference_duration": 10.0
        }
        cache_repo.set(cache_key, cache_data)


def _batch_synthesize_segments(
        vs: VideoWithSubtitles,
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        reference_audio_file: Path,
        cache_repo: CacheRepository,
        cache_key: str
) -> AudioTrack:
    """æ‰¹é‡åˆæˆéŸ³é¢‘ç‰‡æ®µï¼ˆä½¿ç”¨ä¸­æ–‡å­—å¹•ï¼‰"""

    reference_audio_path = reference_audio_file
    #video_processor.extract_reference_audio(vs.video, duration=10.0)

    # âœ… ä½¿ç”¨ç›®æ ‡è¯­è¨€ï¼ˆä¸­æ–‡ï¼‰å­—å¹•
    segments = vs.target_subtitle.segments
    texts = [segment.text for segment in segments]

    print(f"  ğŸ¤ æ‰¹é‡åˆæˆä¸­æ–‡é…éŸ³: {len(texts)} ä¸ªç‰‡æ®µ")

    # æ‰¹é‡åˆæˆ
    synthesized_audios = tts_provider.batch_synthesize(texts=texts, reference_audio_path=reference_audio_path, language=vs.target_subtitle.language)

    # æ‹¼æ¥å®Œæ•´éŸ³é¢‘
    audio_track = _assemble_full_audio(
        synthesized_audios=synthesized_audios,
        segments=segments,
        video_duration=vs.video.duration,
        language=vs.target_subtitle.language
    )

    # ä¿å­˜ç¼“å­˜
    _save_audio_to_cache(
        cache_repo=cache_repo,
        cache_key=cache_key,
        audio_track=audio_track,
        reference_audio_path=reference_audio_path,
        video_path=vs.video.path
    )

    return audio_track


def _skip_voice_cloning(
        video_subtitles: tuple[VideoWithSubtitles, ...],
        progress: Optional[Callable[[float, str], None]]
) -> tuple[VideoWithAudio, ...]:
    """è·³è¿‡è¯­éŸ³å…‹éš†"""
    results = tuple(
        VideoWithAudio(
            video=vs.video,
            original_subtitle=vs.original_subtitle,
            target_subtitle=vs.target_subtitle,
            secondary_subtitle=vs.secondary_subtitle,
            detected_language=vs.detected_language,
            audio_track=None,
            cache_hit_audio=False
        )
        for vs in video_subtitles
    )
    if progress:
        progress(1.0, "é˜¶æ®µ2è·³è¿‡: æœªå¯ç”¨è¯­éŸ³å…‹éš†")
    return results


# ============== é˜¶æ®µæ€§å¤„ç†å‡½æ•° ============== #

def stage1_batch_asr(
        videos: tuple[Video, ...],
        asr_provider: ASRProvider,
        translation_provider: TranslationProvider,
        video_processor: VideoProcessor,
        cache_repo: CacheRepository,
        target_language: LanguageCode = LanguageCode.CHINESE,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[VideoWithSubtitles, ...]:
    """é˜¶æ®µ1: æ‰¹é‡ ASR + ç¿»è¯‘"""

    if progress:
        progress(0.0, "é˜¶æ®µ1: æ‰¹é‡è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘")

    results = []
    total = len(videos)

    for idx, video in enumerate(videos):
        if progress:
            progress(idx / total, f"ASR: å¤„ç†è§†é¢‘ {idx + 1}/{total} - {video.path.name}")

        cache_key = calculate_cache_key(
            video.path,
            "subtitles",
            {"target_language": target_language.value, "source_language": "auto"}
        )

        cache_hit = cache_repo.exists(cache_key)

        if cache_hit:
            try:
                cached = cache_repo.get(cache_key)
                detected_lang = LanguageCode(cached["detected_language"])

                original_subtitle, target_subtitle, secondary_subtitle = \
                    _reconstruct_subtitles_from_cache(cached, detected_lang)

                print(f"  ğŸ’¾ å­—å¹•ç¼“å­˜å‘½ä¸­: {video.path.name}")

            except (KeyError, ValueError) as e:
                print(f"  âš ï¸  å­—å¹•ç¼“å­˜æŸå: {e}ï¼Œé‡æ–°ç”Ÿæˆ")
                cache_hit = False

        if not cache_hit:
            audio_path = video_processor.extract_audio(video)
            original_segments, detected_lang = asr_provider.transcribe(audio_path, None)

            original_subtitle = Subtitle(original_segments, detected_lang)
            target_subtitle, secondary_subtitle = _translate_subtitles(
                original_segments,
                detected_lang,
                translation_provider
            )

            cache_data = {
                "detected_language": detected_lang.value,
                "zh_segments": _serialize_segments(target_subtitle.segments),
                "en_segments": _serialize_segments(secondary_subtitle.segments)
            }

            if detected_lang not in [LanguageCode.CHINESE, LanguageCode.ENGLISH]:
                cache_data[f"{detected_lang.value}_segments"] = _serialize_segments(original_segments)

            cache_repo.set(cache_key, cache_data)
            print(f"  âœ… å®Œæˆ: {video.path.name} ({detected_lang.value} -> zh, en)")

        result = VideoWithSubtitles(
            video=video,
            original_subtitle=original_subtitle,
            target_subtitle=target_subtitle,
            secondary_subtitle=secondary_subtitle,
            detected_language=detected_lang,
            cache_hit_subtitle=cache_hit
        )
        results.append(result)

    if progress:
        progress(1.0, f"é˜¶æ®µ1å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    return tuple(results)


def stage2_batch_tts(
        video_subtitles: tuple[VideoWithSubtitles, ...],
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        cache_repo: CacheRepository,
        enable_voice_cloning: bool = True,
        reference_audio_file: Path = None,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[VideoWithAudio, ...]:
    """é˜¶æ®µ2: æ‰¹é‡ TTSï¼ˆä½¿ç”¨ä¸­æ–‡å­—å¹•ï¼‰"""

    if progress:
        progress(0.0, "é˜¶æ®µ2: æ‰¹é‡è¯­éŸ³å…‹éš†")

    if not enable_voice_cloning:
        return _skip_voice_cloning(video_subtitles, progress)

    results = []
    total = len(video_subtitles)

    for idx, vs in enumerate(video_subtitles):
        if progress:
            progress(idx / total, f"TTS: å¤„ç†è§†é¢‘ {idx + 1}/{total} - {vs.video.path.name}")

        # âœ… ä½¿ç”¨ç›®æ ‡è¯­è¨€ï¼ˆä¸­æ–‡ï¼‰å­—å¹•
        cache_key = calculate_cache_key(
            vs.video.path,
            "voice_cloning",
            {
                "language": vs.target_subtitle.language.value,
                "reference": "auto",
                "num_segments": len(vs.target_subtitle.segments)
            }
        )

        cache_hit = cache_repo.exists(cache_key)
        audio_track = None

        if cache_hit:
            audio_track = _load_audio_from_cache(
                cache_repo,
                cache_key,
                vs.video.path.name,
                vs.target_subtitle.language
            )
            if audio_track is None:
                cache_hit = False

        if not cache_hit:
            audio_track = _batch_synthesize_segments(
                vs=vs,
                tts_provider=tts_provider,
                video_processor=video_processor,
                reference_audio_file=reference_audio_file,
                cache_repo=cache_repo,
                cache_key=cache_key
            )
            print(f"  âœ… å®Œæˆ: {vs.video.path.name}")

        result = VideoWithAudio(
            video=vs.video,
            original_subtitle=vs.original_subtitle,
            target_subtitle=vs.target_subtitle,
            secondary_subtitle=vs.secondary_subtitle,
            detected_language=vs.detected_language,
            audio_track=audio_track,
            cache_hit_audio=cache_hit
        )
        results.append(result)

    if progress:
        progress(1.0, f"é˜¶æ®µ2å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    return tuple(results)


def stage3_batch_synthesis(
        video_audios: tuple[VideoWithAudio, ...],
        video_processor: VideoProcessor,
        subtitle_writer: SubtitleWriter,
        output_dir: Path,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[ProcessedVideo, ...]:
    """é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ"""

    if progress:
        progress(0.0, "é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ")

    results = []
    total = len(video_audios)

    for idx, va in enumerate(video_audios):
        if progress:
            progress(idx / total, f"åˆæˆ: å¤„ç†è§†é¢‘ {idx + 1}/{total} - {va.video.path.name}")

        # âœ… åŒè¯­å­—å¹•ï¼šä¸­æ–‡åœ¨ä¸Šï¼Œè‹±æ–‡åœ¨ä¸‹
        bilingual = merge_bilingual_subtitles(
            va.target_subtitle,
            va.secondary_subtitle
        )

        from application.use_cases.synthesize_video_use_case import synthesize_video_use_case

        synthesis_result = synthesize_video_use_case(
            video=va.video,
            subtitles=(
                va.target_subtitle,
                va.secondary_subtitle,
                bilingual
            ),
            audio_track=va.audio_track,
            video_processor=video_processor,
            subtitle_writer=subtitle_writer,
            output_dir=output_dir,
            burn_subtitles=True,
            progress=None
        )

        processed = ProcessedVideo(
            original_video=va.video,
            subtitles=(va.target_subtitle, va.secondary_subtitle, bilingual),
            audio_tracks=(va.audio_track,) if va.audio_track else tuple(),
            output_paths=synthesis_result.output_paths
        )

        results.append(processed)
        print(f"  âœ… å®Œæˆ: {va.video.path.name}")

    if progress:
        progress(1.0, f"é˜¶æ®µ3å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    return tuple(results)


# ============== ä¸»ç”¨ä¾‹å‡½æ•° ============== #

def batch_process_use_case(
        videos: tuple[Video, ...],
        asr_provider: ASRProvider,
        translation_provider: TranslationProvider,
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        subtitle_writer: SubtitleWriter,
        cache_repo: CacheRepository,
        output_dir: Path,
        enable_voice_cloning: bool = True,
        reference_audio_file: Path = None,
        target_language: LanguageCode = LanguageCode.CHINESE,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[ProcessedVideo, ...]:
    """
    ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†ç”¨ä¾‹ï¼ˆçº¯å‡½æ•°ï¼‰

    æŒ‰é˜¶æ®µæ‰§è¡Œï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹
    """
    if progress:
        progress(0.0, f"å¼€å§‹ä¼˜åŒ–æ‰¹é‡å¤„ç† {len(videos)} ä¸ªè§†é¢‘")

    print(f"\n{'=' * 60}")
    print(f"ğŸš€ ä¼˜åŒ–æ‰¹é‡å¤„ç†æ¨¡å¼")
    print(f"   è§†é¢‘æ•°é‡: {len(videos)}")
    print(f"   è¯­éŸ³å…‹éš†: {'å¯ç”¨' if enable_voice_cloning else 'ç¦ç”¨'}")
    print(f"{'=' * 60}\n")

    # é˜¶æ®µ1
    print(f"ğŸ“ é˜¶æ®µ1: æ‰¹é‡è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘")
    video_subtitles = stage1_batch_asr(
        videos, asr_provider, translation_provider,
        video_processor, cache_repo, target_language,
        lambda p, d: progress(p * 0.4, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ1å®Œæˆ\n")

    # é˜¶æ®µ2
    print(f"ğŸ¤ é˜¶æ®µ2: æ‰¹é‡è¯­éŸ³å…‹éš†")
    video_audios = stage2_batch_tts(
        video_subtitles, tts_provider, video_processor,
        cache_repo, enable_voice_cloning,reference_audio_file,
        lambda p, d: progress(0.4 + p * 0.4, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ2å®Œæˆ\n")

    # é˜¶æ®µ3
    print(f"ğŸ¬ é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ")
    results = stage3_batch_synthesis(
        video_audios, video_processor, subtitle_writer, output_dir,
        lambda p, d: progress(0.8 + p * 0.2, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ3å®Œæˆ\n")

    if progress:
        progress(1.0, "ä¼˜åŒ–æ‰¹é‡å¤„ç†å®Œæˆ")

    # ç»Ÿè®¡
    cache_hits_subtitle = sum(1 for vs in video_subtitles if vs.cache_hit_subtitle)
    cache_hits_audio = sum(1 for va in video_audios if va.cache_hit_audio)

    print(f"\n{'=' * 60}")
    print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ")
    print(f"   æ€»è§†é¢‘æ•°: {len(videos)}")
    print(f"   å­—å¹•ç¼“å­˜å‘½ä¸­: {cache_hits_subtitle}/{len(videos)}")
    if enable_voice_cloning:
        print(f"   éŸ³é¢‘ç¼“å­˜å‘½ä¸­: {cache_hits_audio}/{len(videos)}")
    print(f"   è¾“å‡ºæ–‡ä»¶æ•°: {sum(len(r.output_paths) for r in results)}")
    print(f"{'=' * 60}\n")

    return results