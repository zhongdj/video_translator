"""
ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†ç”¨ä¾‹ - æŒ‰é˜¶æ®µæ‰§è¡Œï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹

è®¾è®¡ç†å¿µï¼š
1. é˜¶æ®µåŒ–å¤„ç†ï¼šASR -> Translation -> TTS -> Synthesis
2. æ¨¡å‹å¤ç”¨ï¼šæ¯ä¸ªé˜¶æ®µçš„æ¨¡å‹åªåŠ è½½ä¸€æ¬¡
3. å‡½æ•°å¼é£æ ¼ï¼šçº¯å‡½æ•° + ä¸å¯å˜æ•°æ®ç»“æ„
4. ç®¡é“æ¨¡å¼ï¼šæ•°æ®åœ¨é˜¶æ®µé—´æµåŠ¨

æ€§èƒ½å¯¹æ¯”ï¼š
- ä¼ ç»Ÿæ–¹å¼ï¼šNä¸ªè§†é¢‘ Ã— 3ä¸ªæ¨¡å‹ = 3Næ¬¡åŠ è½½
- ä¼˜åŒ–æ–¹å¼ï¼š3ä¸ªæ¨¡å‹å„åŠ è½½1æ¬¡ = 3æ¬¡åŠ è½½
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Callable

from domain.entities import (
    Video, Subtitle, AudioTrack, ProcessedVideo,
    LanguageCode,
)
from domain.ports import (
    ASRProvider, TranslationProvider, TTSProvider,
    VideoProcessor, SubtitleWriter, CacheRepository,
)
from domain.services import (
    merge_bilingual_subtitles,
    calculate_cache_key,
)


# ============== ä¸­é—´æ•°æ®ç»“æ„ ============== #

@dataclass(frozen=True)
class VideoWithSubtitles:
    """è§†é¢‘ + å­—å¹•çš„ä¸­é—´ç»“æœ"""
    video: Video
    original_subtitle: Subtitle
    translated_subtitle: Subtitle
    detected_language: LanguageCode
    cache_hit_subtitle: bool


@dataclass(frozen=True)
class VideoWithAudio:
    """è§†é¢‘ + å­—å¹• + éŸ³é¢‘çš„ä¸­é—´ç»“æœ"""
    video: Video
    original_subtitle: Subtitle
    translated_subtitle: Subtitle
    detected_language: LanguageCode
    audio_track: Optional[AudioTrack]
    cache_hit_audio: bool


# ============== é˜¶æ®µæ€§å¤„ç†å‡½æ•° ============== #

def stage1_batch_asr(
        videos: tuple[Video, ...],
        asr_provider: ASRProvider,
        translation_provider: TranslationProvider,
        video_processor: VideoProcessor,
        cache_repo: CacheRepository,
        target_language: LanguageCode = LanguageCode.CHINESE,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[VideoWithSubtitles, ...]:
    """
    é˜¶æ®µ1: æ‰¹é‡ ASR + ç¿»è¯‘

    å¯¹æ‰€æœ‰è§†é¢‘æ‰§è¡Œè¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘ï¼Œæ¨¡å‹åªåŠ è½½ä¸€æ¬¡
    """
    if progress:
        progress(0.0, "é˜¶æ®µ1: æ‰¹é‡è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘")

    results = []
    total = len(videos)

    for idx, video in enumerate(videos):
        video_progress = idx / total

        if progress:
            progress(video_progress, f"ASR: å¤„ç†è§†é¢‘ {idx + 1}/{total} - {video.path.name}")

        # æ£€æŸ¥ç¼“å­˜
        cache_key = calculate_cache_key(
            video.path,
            "subtitles",
            {
                "target_language": target_language.value,
                "source_language": "auto"
            }
        )

        cache_hit = cache_repo.exists(cache_key)

        if cache_hit:
            # ä»ç¼“å­˜åŠ è½½
            cached = cache_repo.get(cache_key)
            detected_lang = LanguageCode(cached["detected_language"])

            from domain.entities import TextSegment, TimeRange

            original_segments = tuple(
                TextSegment(
                    text=seg["text"],
                    time_range=TimeRange(seg["start"], seg["end"]),
                    language=detected_lang
                )
                for seg in cached.get(f"{detected_lang.value}_segments", [])
            )

            zh_segments = tuple(
                TextSegment(
                    text=seg["text"],
                    time_range=TimeRange(seg["start"], seg["end"]),
                    language=LanguageCode.CHINESE
                )
                for seg in cached.get("zh_segments", [])
            )

            original_subtitle = Subtitle(original_segments, detected_lang) if original_segments else Subtitle(
                zh_segments, detected_lang)
            translated_subtitle = Subtitle(zh_segments, LanguageCode.CHINESE)

            print(f"  ğŸ’¾ ç¼“å­˜å‘½ä¸­: {video.path.name}")
        else:
            # æ‰§è¡Œ ASR
            audio_path = video_processor.extract_audio(video)
            original_segments, detected_lang = asr_provider.transcribe(audio_path, None)

            # æ‰§è¡Œç¿»è¯‘
            from domain.entities import TextSegment

            en_segments = None
            zh_segments = None

            if detected_lang == LanguageCode.ENGLISH:
                en_segments = original_segments
                zh_segments = translation_provider.translate(
                    original_segments,
                    LanguageCode.ENGLISH,
                    LanguageCode.CHINESE
                )
            elif detected_lang == LanguageCode.CHINESE:
                zh_segments = original_segments
                en_segments = translation_provider.translate(
                    original_segments,
                    LanguageCode.CHINESE,
                    LanguageCode.ENGLISH
                )
            else:
                # å…¶ä»–è¯­è¨€ï¼šå…ˆç¿»è¯‘åˆ°è‹±æ–‡ï¼Œå†ç¿»è¯‘åˆ°ä¸­æ–‡
                en_segments = translation_provider.translate(
                    original_segments,
                    detected_lang,
                    LanguageCode.ENGLISH
                )
                zh_segments = translation_provider.translate(
                    en_segments,
                    LanguageCode.ENGLISH,
                    LanguageCode.CHINESE
                )

            # ä¿å­˜ç¼“å­˜
            cache_data = {
                "detected_language": detected_lang.value,
                "zh_segments": [
                    {"text": seg.text, "start": seg.time_range.start_seconds, "end": seg.time_range.end_seconds}
                    for seg in zh_segments
                ],
                "en_segments": [
                    {"text": seg.text, "start": seg.time_range.start_seconds, "end": seg.time_range.end_seconds}
                    for seg in en_segments
                ]
            }

            if detected_lang not in [LanguageCode.CHINESE, LanguageCode.ENGLISH]:
                cache_data[f"{detected_lang.value}_segments"] = [
                    {"text": seg.text, "start": seg.time_range.start_seconds, "end": seg.time_range.end_seconds}
                    for seg in original_segments
                ]

            cache_repo.set(cache_key, cache_data)

            original_subtitle = Subtitle(original_segments, detected_lang)
            translated_subtitle = Subtitle(zh_segments, LanguageCode.CHINESE)

            print(f"  âœ… å®Œæˆ: {video.path.name} ({detected_lang.value} -> zh)")

        # æ„å»ºä¸­é—´ç»“æœ
        result = VideoWithSubtitles(
            video=video,
            original_subtitle=original_subtitle,
            translated_subtitle=translated_subtitle,
            detected_language=detected_lang,
            cache_hit_subtitle=cache_hit
        )
        results.append(result)

    if progress:
        progress(1.0, f"é˜¶æ®µ1å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    return tuple(results)


def stage2_batch_tts(
        video_subtitles: tuple[VideoWithSubtitles, ...],
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        cache_repo: CacheRepository,
        enable_voice_cloning: bool = True,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[VideoWithAudio, ...]:
    """
    é˜¶æ®µ2: æ‰¹é‡ TTSï¼ˆè¯­éŸ³å…‹éš†ï¼‰

    å¯¹æ‰€æœ‰è§†é¢‘æ‰§è¡Œè¯­éŸ³åˆæˆï¼ŒTTS æ¨¡å‹åªåŠ è½½ä¸€æ¬¡
    """
    if progress:
        progress(0.0, "é˜¶æ®µ2: æ‰¹é‡è¯­éŸ³å…‹éš†")

    if not enable_voice_cloning:
        # è·³è¿‡è¯­éŸ³å…‹éš†ï¼Œç›´æ¥è¿”å›
        results = tuple(
            VideoWithAudio(
                video=vs.video,
                original_subtitle=vs.original_subtitle,
                translated_subtitle=vs.translated_subtitle,
                detected_language=vs.detected_language,
                audio_track=None,
                cache_hit_audio=False
            )
            for vs in video_subtitles
        )
        if progress:
            progress(1.0, "é˜¶æ®µ2è·³è¿‡: æœªå¯ç”¨è¯­éŸ³å…‹éš†")
        return results

    results = []
    total = len(video_subtitles)

    for idx, vs in enumerate(video_subtitles):
        video_progress = idx / total

        if progress:
            progress(video_progress, f"TTS: å¤„ç†è§†é¢‘ {idx + 1}/{total} - {vs.video.path.name}")

        # æ£€æŸ¥ç¼“å­˜
        cache_key = calculate_cache_key(
            vs.video.path,
            "voice_cloning",
            {
                "language": vs.translated_subtitle.language.value,
                "reference": "auto",
                "num_segments": len(vs.translated_subtitle.segments)
            }
        )

        cache_hit = cache_repo.exists(cache_key)

        if cache_hit:
            # ä»ç¼“å­˜åŠ è½½
            cached = cache_repo.get(cache_key)

            from domain.entities import AudioSample, VoiceProfile

            audio_sample = AudioSample(
                samples=tuple(cached["audio_samples"]),
                sample_rate=cached["sample_rate"]
            )

            audio_track = AudioTrack(audio_sample, vs.translated_subtitle.language)

            print(f"  ğŸ’¾ ç¼“å­˜å‘½ä¸­: {vs.video.path.name}")
        else:
            # æå–å‚è€ƒéŸ³é¢‘
            reference_audio_path = video_processor.extract_reference_audio(
                vs.video,
                10.0
            )

            # åˆ›å»ºå£°éŸ³é…ç½®
            from domain.entities import VoiceProfile

            voice_profile = VoiceProfile(
                reference_audio_path=reference_audio_path,
                language=vs.translated_subtitle.language,
                duration=10.0
            )

            # é€å¥åˆæˆ
            synthesized_segments = []
            for seg_idx, segment in enumerate(vs.translated_subtitle.segments):
                audio_sample = tts_provider.synthesize(
                    text=segment.text,
                    voice_profile=voice_profile,
                    target_duration=segment.time_range.duration
                )
                synthesized_segments.append((audio_sample, segment))

            # æ‹¼æ¥éŸ³é¢‘
            total_samples = int(vs.video.duration * synthesized_segments[0][0].sample_rate)
            full_audio_list = [0.0] * total_samples

            for audio_sample, segment in synthesized_segments:
                start_idx = int(segment.time_range.start_seconds * audio_sample.sample_rate)
                for i, sample in enumerate(audio_sample.samples):
                    if start_idx + i < total_samples:
                        full_audio_list[start_idx + i] = sample

            from domain.entities import AudioSample

            full_audio = AudioSample(
                samples=tuple(full_audio_list),
                sample_rate=synthesized_segments[0][0].sample_rate
            )

            # ä¿å­˜ç¼“å­˜
            cache_data = {
                "audio_samples": list(full_audio.samples),
                "sample_rate": full_audio.sample_rate,
                "reference_audio": str(reference_audio_path),
                "reference_duration": 10.0
            }
            cache_repo.set(cache_key, cache_data)

            audio_track = AudioTrack(full_audio, vs.translated_subtitle.language)

            print(f"  âœ… å®Œæˆ: {vs.video.path.name}")

        # æ„å»ºä¸­é—´ç»“æœ
        result = VideoWithAudio(
            video=vs.video,
            original_subtitle=vs.original_subtitle,
            translated_subtitle=vs.translated_subtitle,
            detected_language=vs.detected_language,
            audio_track=audio_track,
            cache_hit_audio=cache_hit
        )
        results.append(result)

    if progress:
        progress(1.0, f"é˜¶æ®µ2å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    return tuple(results)


def stage3_batch_synthesis(
        video_audios: tuple[VideoWithAudio, ...],
        video_processor: VideoProcessor,
        subtitle_writer: SubtitleWriter,
        output_dir: Path,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[ProcessedVideo, ...]:
    """
    é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ

    ä¸ºæ‰€æœ‰è§†é¢‘ç”Ÿæˆå­—å¹•æ–‡ä»¶å’Œæœ€ç»ˆè§†é¢‘
    """
    if progress:
        progress(0.0, "é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ")

    results = []
    total = len(video_audios)

    for idx, va in enumerate(video_audios):
        video_progress = idx / total

        if progress:
            progress(video_progress, f"åˆæˆ: å¤„ç†è§†é¢‘ {idx + 1}/{total} - {va.video.path.name}")

        # åˆ›å»ºåŒè¯­å­—å¹•
        bilingual = merge_bilingual_subtitles(
            va.translated_subtitle,
            va.original_subtitle
        )

        # æ‰§è¡Œè§†é¢‘åˆæˆ
        from application.use_cases.synthesize_video_use_case import synthesize_video_use_case

        synthesis_result = synthesize_video_use_case(
            video=va.video,
            subtitles=(
                va.translated_subtitle,
                va.original_subtitle,
                bilingual
            ),
            audio_track=va.audio_track,
            video_processor=video_processor,
            subtitle_writer=subtitle_writer,
            output_dir=output_dir,
            burn_subtitles=True,
            progress=None  # ä¸ä¼ é€’è¿›åº¦ï¼Œé¿å…è¿‡å¤šè¾“å‡º
        )

        # æ„å»ºç»“æœ
        processed = ProcessedVideo(
            original_video=va.video,
            subtitles=(
                va.translated_subtitle,
                va.original_subtitle,
                bilingual
            ),
            audio_tracks=(va.audio_track,) if va.audio_track else tuple(),
            output_paths=synthesis_result.output_paths
        )

        results.append(processed)
        print(f"  âœ… å®Œæˆ: {va.video.path.name}")

    if progress:
        progress(1.0, f"é˜¶æ®µ3å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    return tuple(results)


# ============== ä¸»ç”¨ä¾‹å‡½æ•° ============== #

def batch_process_use_case(
        videos: tuple[Video, ...],
        asr_provider: ASRProvider,
        translation_provider: TranslationProvider,
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        subtitle_writer: SubtitleWriter,
        cache_repo: CacheRepository,
        output_dir: Path,
        enable_voice_cloning: bool = True,
        target_language: LanguageCode = LanguageCode.CHINESE,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[ProcessedVideo, ...]:
    """
    ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†ç”¨ä¾‹ï¼ˆçº¯å‡½æ•°ï¼‰

    æŒ‰é˜¶æ®µæ‰§è¡Œï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹ï¼š
    1. é˜¶æ®µ1: æ‰¹é‡ ASR + ç¿»è¯‘ï¼ˆæ‰€æœ‰è§†é¢‘ï¼‰
    2. é˜¶æ®µ2: æ‰¹é‡ TTSï¼ˆæ‰€æœ‰è§†é¢‘ï¼‰
    3. é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆï¼ˆæ‰€æœ‰è§†é¢‘ï¼‰

    æ€§èƒ½æå‡ï¼š
    - ä¼ ç»Ÿæ–¹å¼ï¼š3N æ¬¡æ¨¡å‹åŠ è½½ï¼ˆN = è§†é¢‘æ•°é‡ï¼‰
    - ä¼˜åŒ–æ–¹å¼ï¼š3 æ¬¡æ¨¡å‹åŠ è½½ï¼ˆæ¯ç§æ¨¡å‹åŠ è½½1æ¬¡ï¼‰

    Args:
        videos: å¾…å¤„ç†çš„è§†é¢‘åˆ—è¡¨
        asr_provider: ASR æä¾›è€…
        translation_provider: ç¿»è¯‘æä¾›è€…
        tts_provider: TTS æä¾›è€…
        video_processor: è§†é¢‘å¤„ç†å™¨
        subtitle_writer: å­—å¹•å†™å…¥å™¨
        cache_repo: ç¼“å­˜ä»“å‚¨
        output_dir: è¾“å‡ºç›®å½•
        enable_voice_cloning: æ˜¯å¦å¯ç”¨è¯­éŸ³å…‹éš†
        target_language: ç›®æ ‡è¯­è¨€
        progress: è¿›åº¦å›è°ƒ

    Returns:
        å¤„ç†ç»“æœåˆ—è¡¨
    """
    if progress:
        progress(0.0, f"å¼€å§‹ä¼˜åŒ–æ‰¹é‡å¤„ç† {len(videos)} ä¸ªè§†é¢‘")

    print(f"\n{'=' * 60}")
    print(f"ğŸš€ ä¼˜åŒ–æ‰¹é‡å¤„ç†æ¨¡å¼")
    print(f"   è§†é¢‘æ•°é‡: {len(videos)}")
    print(f"   è¯­éŸ³å…‹éš†: {'å¯ç”¨' if enable_voice_cloning else 'ç¦ç”¨'}")
    print(f"{'=' * 60}\n")

    # é˜¶æ®µ1: æ‰¹é‡ ASR + ç¿»è¯‘
    print(f"ğŸ“ é˜¶æ®µ1: æ‰¹é‡è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘")
    video_subtitles = stage1_batch_asr(
        videos=videos,
        asr_provider=asr_provider,
        translation_provider=translation_provider,
        video_processor=video_processor,
        cache_repo=cache_repo,
        target_language=target_language,
        progress=lambda p, d: progress(p * 0.4, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ1å®Œæˆ\n")

    # é˜¶æ®µ2: æ‰¹é‡ TTS
    print(f"ğŸ¤ é˜¶æ®µ2: æ‰¹é‡è¯­éŸ³å…‹éš†")
    video_audios = stage2_batch_tts(
        video_subtitles=video_subtitles,
        tts_provider=tts_provider,
        video_processor=video_processor,
        cache_repo=cache_repo,
        enable_voice_cloning=enable_voice_cloning,
        progress=lambda p, d: progress(0.4 + p * 0.4, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ2å®Œæˆ\n")

    # é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ
    print(f"ğŸ¬ é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ")
    results = stage3_batch_synthesis(
        video_audios=video_audios,
        video_processor=video_processor,
        subtitle_writer=subtitle_writer,
        output_dir=output_dir,
        progress=lambda p, d: progress(0.8 + p * 0.2, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ3å®Œæˆ\n")

    if progress:
        progress(1.0, "ä¼˜åŒ–æ‰¹é‡å¤„ç†å®Œæˆ")

    # ç»Ÿè®¡ä¿¡æ¯
    cache_hits_subtitle = sum(1 for vs in video_subtitles if vs.cache_hit_subtitle)
    cache_hits_audio = sum(1 for va in video_audios if va.cache_hit_audio)

    print(f"\n{'=' * 60}")
    print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ")
    print(f"   æ€»è§†é¢‘æ•°: {len(videos)}")
    print(f"   å­—å¹•ç¼“å­˜å‘½ä¸­: {cache_hits_subtitle}/{len(videos)}")
    if enable_voice_cloning:
        print(f"   éŸ³é¢‘ç¼“å­˜å‘½ä¸­: {cache_hits_audio}/{len(videos)}")
    print(f"   è¾“å‡ºæ–‡ä»¶æ•°: {sum(len(r.output_paths) for r in results)}")
    print(f"{'=' * 60}\n")

    return results