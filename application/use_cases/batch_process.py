"""
ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†ç”¨ä¾‹ - ä¿®å¤å­—å¹•é€»è¾‘ç‰ˆæœ¬

å…³é”®ä¿®å¤ï¼š
1. âœ… å­—å¹•å‘½åæ¸…æ™°ï¼šoriginal/target/secondary
2. âœ… TTS ä½¿ç”¨ç›®æ ‡è¯­è¨€ï¼ˆä¸­æ–‡ï¼‰å­—å¹•
3. âœ… åŒè¯­å­—å¹•é¡ºåºæ­£ç¡®ï¼ˆä¸­æ–‡åœ¨ä¸Šï¼Œè‹±æ–‡åœ¨ä¸‹ï¼‰
4. âœ… å®Œæ•´çš„å¯¼å…¥å’Œè¾…åŠ©å‡½æ•°
"""

from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Callable, List, Tuple

from domain.entities import (
    Video, Subtitle, AudioTrack, ProcessedVideo,
    LanguageCode, AudioSample, TextSegment, TimeRange, VoiceProfile
)
from domain.ports import (
    ASRProvider, TranslationProvider, TTSProvider,
    VideoProcessor, SubtitleWriter, CacheRepository,
    AudioFileRepository,
)
from domain.services import (
    merge_bilingual_subtitles,
    calculate_cache_key,
)

# ============== ä¸­é—´æ•°æ®ç»“æ„ ============== #
@dataclass(frozen=True)
class VideoWithSubtitles:
    """
    è§†é¢‘ + å­—å¹•çš„ä¸­é—´ç»“æœ

    å­—å¹•å‘½åè§„èŒƒï¼š
    - original_subtitle: ASRè¯†åˆ«çš„åŸå§‹è¯­è¨€å­—å¹•
    - target_subtitle: ç›®æ ‡è¯­è¨€å­—å¹•ï¼ˆä¸­æ–‡ï¼‰
    - secondary_subtitle: æ¬¡è¦è¯­è¨€å­—å¹•ï¼ˆè‹±æ–‡ï¼‰
    """
    video: Video
    original_subtitle: Subtitle  # åŸå§‹è¯†åˆ«è¯­è¨€ï¼ˆzh/en/pt/jaç­‰ï¼‰
    target_subtitle: Subtitle  # ç›®æ ‡è¯­è¨€ï¼ˆä¸­æ–‡ï¼‰
    secondary_subtitle: Subtitle  # æ¬¡è¦è¯­è¨€ï¼ˆè‹±æ–‡ï¼‰
    detected_language: LanguageCode
    cache_hit_subtitle: bool = False


@dataclass(frozen=True)
class VideoWithAudio:
    """è§†é¢‘ + å­—å¹• + éŸ³é¢‘çš„ä¸­é—´ç»“æœ"""
    video: Video
    original_subtitle: Subtitle
    target_subtitle: Subtitle  # ä¸­æ–‡å­—å¹•
    secondary_subtitle: Subtitle  # è‹±æ–‡å­—å¹•
    detected_language: LanguageCode
    audio_track: Optional[AudioTrack]
    cache_hit_audio: bool


# ============== è¾…åŠ©å‡½æ•°ï¼ˆçº¯é€»è¾‘ï¼‰ ============== #
def _serialize_segments(segments: tuple[TextSegment, ...]) -> list:
    """åºåˆ—åŒ–æ–‡æœ¬ç‰‡æ®µä¸ºå­—å…¸åˆ—è¡¨"""
    return [
        {
            "text": seg.text,
            "start": seg.time_range.start_seconds,
            "end": seg.time_range.end_seconds
        }
        for seg in segments
    ]


def _deserialize_segments(
    data: List[dict],
    language: LanguageCode
) -> Tuple[TextSegment, ...]:
    """ååºåˆ—åŒ–æ–‡æœ¬ç‰‡æ®µ"""
    return tuple(
        TextSegment(
            text=item["text"],
            time_range=TimeRange(
                start_seconds=item["start"],
                end_seconds=item["end"],
            ),
            language=language
        )
        for item in data
    )


# ============== éŸ³é¢‘å¤„ç†ï¼ˆé‡æ„ç‰ˆï¼‰ ============== #
def _load_audio_from_cache(
        audio_repo: AudioFileRepository,  # âœ… ä½¿ç”¨Portæ¥å£
        cache_key: str,
        language: LanguageCode
) -> Optional[AudioTrack]:
    """ä»ç¼“å­˜åŠ è½½éŸ³é¢‘è½¨é“ï¼ˆçº¯å‡½æ•°ï¼‰"""
    audio_sample, metadata = audio_repo.load_audio(cache_key)

    if audio_sample is None:
        return None

    return AudioTrack(audio_sample, language)


def _save_audio_to_cache(
        audio_repo: AudioFileRepository,  # âœ… ä½¿ç”¨Portæ¥å£
        cache_key: str,
        audio_track: AudioTrack,
        reference_audio_path: Path
) -> None:
    """ä¿å­˜éŸ³é¢‘åˆ°ç¼“å­˜ï¼ˆçº¯å‡½æ•°ï¼‰"""
    metadata = {
        "language": audio_track.language.value,
        "sample_rate": audio_track.audio.sample_rate,
        "reference_audio": str(reference_audio_path),
    }

    audio_repo.save_audio(cache_key, audio_track.audio, metadata)


def _assemble_full_audio(
        synthesized_audios: tuple,
        segments: tuple[TextSegment, ...],
        video_duration: float,
        language: LanguageCode
) -> AudioTrack:
    """æ‹¼æ¥éŸ³é¢‘ç‰‡æ®µï¼ˆçº¯é€»è¾‘ï¼‰"""
    if not synthesized_audios:
        raise ValueError("æ²¡æœ‰å¯æ‹¼æ¥çš„éŸ³é¢‘")

    sample_rate = synthesized_audios[0].sample_rate
    total_samples = int(video_duration * sample_rate)
    full_audio_list = [0.0] * total_samples

    for audio_sample, segment in zip(synthesized_audios, segments):
        start_idx = int(segment.time_range.start_seconds * sample_rate)
        for i, sample in enumerate(audio_sample.samples):
            target_idx = start_idx + i
            if target_idx < total_samples:
                full_audio_list[target_idx] = sample

    full_audio = AudioSample(
        samples=tuple(full_audio_list),
        sample_rate=sample_rate
    )

    return AudioTrack(full_audio, language)


# ============== å­—å¹•ç¼“å­˜è¾…åŠ©å‡½æ•° ============== #
def _load_subtitle_segments(
        cached_data: dict,
        language: LanguageCode,
        segment_key: str
) -> tuple[TextSegment, ...]:
    """ä»ç¼“å­˜åŠ è½½æŒ‡å®šè¯­è¨€çš„å­—å¹•ç‰‡æ®µ"""
    segments_data = cached_data.get(segment_key, [])
    if not segments_data:
        return tuple()

    return tuple(
        TextSegment(
            text=seg["text"],
            time_range=TimeRange(seg["start"], seg["end"]),
            language=language
        )
        for seg in segments_data
    )


def _reconstruct_subtitles_from_cache(
        cached: dict,
        detected_lang: LanguageCode
) -> tuple[Subtitle, Subtitle, Subtitle]:
    """
    ä»ç¼“å­˜é‡å»ºæ‰€æœ‰å­—å¹•

    Returns:
        (original_subtitle, target_subtitle, secondary_subtitle)
    """
    # 1. æ¢å¤ä¸­æ–‡å­—å¹•ï¼ˆç›®æ ‡è¯­è¨€ï¼‰
    zh_segments = _load_subtitle_segments(cached, LanguageCode.CHINESE, "zh_segments")
    target_subtitle = Subtitle(zh_segments, LanguageCode.CHINESE)

    # 2. æ¢å¤è‹±æ–‡å­—å¹•ï¼ˆæ¬¡è¦è¯­è¨€ï¼‰
    en_segments = _load_subtitle_segments(cached, LanguageCode.ENGLISH, "en_segments")
    secondary_subtitle = Subtitle(en_segments, LanguageCode.ENGLISH)

    # 3. æ¢å¤åŸå§‹è¯­è¨€å­—å¹•
    if detected_lang == LanguageCode.CHINESE:
        original_subtitle = target_subtitle
    elif detected_lang == LanguageCode.ENGLISH:
        original_subtitle = secondary_subtitle
    else:
        original_segments = _load_subtitle_segments(
            cached,
            detected_lang,
            f"{detected_lang.value}_segments"
        )
        if original_segments:
            original_subtitle = Subtitle(original_segments, detected_lang)
        else:
            original_subtitle = target_subtitle

    return original_subtitle, target_subtitle, secondary_subtitle

# ============== å­—å¹•ç¿»è¯‘ç­–ç•¥å‡½æ•° ============== #

def _translate_subtitles(
        original_segments: tuple[TextSegment, ...],
        detected_lang: LanguageCode,
        translation_provider: TranslationProvider
) -> tuple[Subtitle, Subtitle]:
    """
    ç¿»è¯‘å­—å¹•ï¼Œå§‹ç»ˆè¿”å›ä¸­æ–‡å­—å¹•å’Œè‹±æ–‡å­—å¹•

    Returns:
        (target_subtitle: ä¸­æ–‡, secondary_subtitle: è‹±æ–‡)
    """
    if detected_lang == LanguageCode.CHINESE:
        zh_segments = original_segments
        en_segments = translation_provider.translate(
            original_segments,
            LanguageCode.CHINESE,
            LanguageCode.ENGLISH
        )

    elif detected_lang == LanguageCode.ENGLISH:
        en_segments = original_segments
        zh_segments = translation_provider.translate(
            original_segments,
            LanguageCode.ENGLISH,
            LanguageCode.CHINESE
        )

    else:
        en_segments = translation_provider.translate(
            original_segments,
            detected_lang,
            LanguageCode.ENGLISH
        )
        zh_segments = translation_provider.translate(
            en_segments,
            LanguageCode.ENGLISH,
            LanguageCode.CHINESE
        )

    target_subtitle = Subtitle(zh_segments, LanguageCode.CHINESE)
    secondary_subtitle = Subtitle(en_segments, LanguageCode.ENGLISH)

    return target_subtitle, secondary_subtitle

# ============== é˜¶æ®µæ€§å¤„ç†å‡½æ•° ============== #
def phase1_extract_asr(
        videos: List[Video],
        cache_repo: CacheRepository,
        video_processor: VideoProcessor,
        asr_provider: ASRProvider,
        progress: Optional[Callable[[float, str], None]] = None,
) -> Tuple[VideoWithSubtitles, ...]:
    """
    éŸ³é¢‘æå– + ASRï¼Œç»“æœè½ç›˜å¹¶è¿”å› VideoWithSubtitlesï¼ˆåŸå§‹å­—å¹•ï¼‰ã€‚
    """
    total = len(videos)
    out: List[VideoWithSubtitles] = []

    for idx, video in enumerate(videos):
        if progress:
            progress(idx / total, f"Phase-1 ASR: {idx + 1}/{total}  {video.path.name}")

        cache_key = calculate_cache_key(video.path, "phase1_asr", {})
        if cache_repo.exists(cache_key):
            try:
                cached = cache_repo.get(cache_key)
                detected_lang = LanguageCode(cached["detected_language"])
                original_sub = Subtitle(
                    segments=_deserialize_segments(cached["segments"], detected_lang),
                    language=detected_lang,
                )
                out.append(VideoWithSubtitles(video, original_sub, None, None, detected_lang, True))
                print(f"  ğŸ’¾ Phase-1 ç¼“å­˜å‘½ä¸­: {video.path.name}")
                continue
            except (KeyError, ValueError):
                print(f"  âš ï¸  Phase-1 ç¼“å­˜æŸåï¼Œé‡æ–°ç”Ÿæˆ: {video.path.name}")

        # çœŸæ­£å¹²æ´»
        audio_path = video_processor.extract_audio(video)
        segments, detected_lang = asr_provider.transcribe(audio_path)
        cache_repo.set(cache_key, {
            "detected_language": detected_lang.value,
            "segments": _serialize_segments(segments),
        })
        original_sub = Subtitle(segments, detected_lang)
        out.append(VideoWithSubtitles(video, original_sub, None, None, detected_lang, False))
        print(f"  âœ… Phase-1 å®Œæˆ: {video.path.name}  ({detected_lang.value})")

    return tuple(out)

def phase2_translate(
        videos: List[Video],
        cache_repo: CacheRepository,
        translation_provider: TranslationProvider,
        target_language: LanguageCode = LanguageCode.CHINESE,
        progress: Optional[Callable[[float, str], None]] = None,
) -> Tuple[VideoWithSubtitles, ...]:
    """
    è¯»å– Phase-1 ç¼“å­˜ â†’ ç¿»è¯‘ï¼ˆæˆ–ç¼“å­˜å‘½ä¸­ï¼‰â†’ è¿”å› VideoWithSubtitles å…ƒç»„
    """
    total = len(videos)
    out: List[VideoWithSubtitles] = []

    for idx, video in enumerate(videos):
        if progress:
            progress(idx / total, f"Phase-2 Trans: {idx + 1}/{total}  {video.path.name}")

        # 1. Phase-2 ç¼“å­˜ key
        trans_key = calculate_cache_key(
            video.path,
            "phase2_trans",
            {"target_language": target_language.value},
        )

        # 2. è¯» Phase-1 åŸå§‹å­—å¹•ï¼ˆå¿…é¡»å­˜åœ¨ï¼‰
        asr_key = calculate_cache_key(video.path, "phase1_asr", {})
        if not cache_repo.exists(asr_key):
            raise RuntimeError(f"Phase-1 ç¼“å­˜ç¼ºå¤±ï¼Œæ— æ³•ç¿»è¯‘: {video.path.name}")
        asr_cached = cache_repo.get(asr_key)
        detected_lang = LanguageCode(asr_cached["detected_language"])
        original_sub = Subtitle(
            segments=_deserialize_segments(asr_cached["segments"], detected_lang),
            language=detected_lang,
        )

        # 3. å¦‚æœ Phase-2 å·²å­˜åœ¨ï¼Œç›´æ¥è¿˜åŸ
        if cache_repo.exists(trans_key):
            try:
                trans_cached = cache_repo.get(trans_key)
                zh_sub = Subtitle(
                    segments=_deserialize_segments(trans_cached["zh_segments"], _deserialize_segments),
                    language=LanguageCode.CHINESE,
                )
                en_sub = Subtitle(
                    segments=_deserialize_segments(trans_cached["en_segments"], _deserialize_segments),
                    language=LanguageCode.ENGLISH,
                )
                out.append(VideoWithSubtitles(video, original_sub, zh_sub, en_sub, detected_lang, True))
                print(f"  ğŸ’¾ Phase-2 ç¼“å­˜å‘½ä¸­: {video.path.name}")
                continue
            except (KeyError, ValueError):
                print(f"  âš ï¸  Phase-2 ç¼“å­˜æŸåï¼Œé‡æ–°ç¿»è¯‘: {video.path.name}")

        # 4. çœŸæ­£ç¿»è¯‘
        zh_sub, en_sub = _translate_subtitles(
            original_sub.segments,
            detected_lang,
            translation_provider,
        )

        # 5. å†™ Phase-2 ç¼“å­˜
        cache_repo.set(
            trans_key,
            {
                "zh_segments": _serialize_segments(zh_sub.segments),
                "en_segments": _serialize_segments(en_sub.segments),
            },
        )
        out.append(out.append(VideoWithSubtitles(
            video=video,
            original_subtitle=original_sub,
            target_subtitle=zh_sub,  # ä¸­æ–‡ç•™ç©º
            secondary_subtitle=en_sub,  # è‹±æ–‡ç•™ç©º
            detected_language=detected_lang,
            cache_hit_subtitle=False  # æˆ– Falseï¼Œè§†ä½ é€»è¾‘è€Œå®š
        )))
        print(f"  âœ… Phase-2 å®Œæˆ: {video.path.name}")

    return tuple(out)


def stage1_batch_asr(
        videos: tuple[Video, ...],
        asr_provider: ASRProvider,
        translation_provider: TranslationProvider,
        video_processor: VideoProcessor,
        cache_repo: CacheRepository,
        target_language: LanguageCode = LanguageCode.CHINESE,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[VideoWithSubtitles, ...]:
    """é˜¶æ®µ1: æ‰¹é‡ ASR + ç¿»è¯‘"""

    if progress:
        progress(0.0, "é˜¶æ®µ1: æ‰¹é‡è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘")

    total = len(videos)

    videos_with_orig = phase1_extract_asr(list(videos), cache_repo, video_processor, asr_provider, progress)
    asr_provider.unload()

    videos_with_subs = phase2_translate(
        videos=[vws.video for vws in videos_with_orig],
        cache_repo=cache_repo,
        translation_provider=translation_provider,
        target_language=target_language,
        progress=lambda ratio, msg: print(f"{ratio:.1%} {msg}"),
    )
    translation_provider.unload()

    if progress:
        progress(1.0, f"é˜¶æ®µ1å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    del video_processor, asr_provider, translation_provider
    return tuple(videos_with_subs)


def stage2_batch_tts(
        video_subtitles: tuple,
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        cache_repo: CacheRepository,
        audio_repo: AudioFileRepository,  # âœ… æ–°å¢å‚æ•°
        enable_voice_cloning: bool = True,
        reference_audio_file: Path = None,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple:
    """é˜¶æ®µ2: æ‰¹é‡TTSï¼ˆé‡æ„ç‰ˆï¼‰"""

    if not enable_voice_cloning:
        return _skip_voice_cloning(video_subtitles, progress)

    results = []
    total = len(video_subtitles)

    for idx, vs in enumerate(video_subtitles):
        if progress:
            progress(idx / total, f"TTS: {idx + 1}/{total} - {vs.video.path.name}")

        cache_key = calculate_cache_key(
            vs.video.path,
            "voice_cloning",
            {
                "language": vs.target_subtitle.language.value,
                "num_segments": len(vs.target_subtitle.segments)
            }
        )

        # âœ… ä½¿ç”¨Portæ¥å£æ£€æŸ¥ç¼“å­˜
        cache_hit = audio_repo.exists(cache_key)
        audio_track = None

        if cache_hit:
            audio_track = _load_audio_from_cache(
                audio_repo,
                cache_key,
                vs.target_subtitle.language
            )
            if audio_track is None:
                cache_hit = False

        if not cache_hit:
            # æ‰¹é‡åˆæˆ
            texts = [seg.text for seg in vs.target_subtitle.segments]
            synthesized_audios = tts_provider.batch_synthesize(
                texts=texts,
                reference_audio_path=reference_audio_file,
                language=vs.target_subtitle.language
            )

            # æ‹¼æ¥éŸ³é¢‘
            audio_track = _assemble_full_audio(
                synthesized_audios=synthesized_audios,
                segments=vs.target_subtitle.segments,
                video_duration=vs.video.duration,
                language=vs.target_subtitle.language
            )

            # âœ… ä½¿ç”¨Portæ¥å£ä¿å­˜
            _save_audio_to_cache(
                audio_repo,
                cache_key,
                audio_track,
                reference_audio_file
            )

        # æ„å»ºç»“æœ
        result = VideoWithAudio(
            video=vs.video,
            original_subtitle=vs.original_subtitle,
            target_subtitle=vs.target_subtitle,
            secondary_subtitle=vs.secondary_subtitle,
            detected_language=vs.detected_language,
            audio_track=audio_track,
            cache_hit_audio=cache_hit
        )
        results.append(result)

    if progress:
        progress(1.0, f"é˜¶æ®µ2å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    tts_provider.unload()
    return tuple(results)


def _skip_voice_cloning(video_subtitles, progress):
    """è·³è¿‡è¯­éŸ³å…‹éš†çš„è¾…åŠ©å‡½æ•°"""

    results = tuple(
        VideoWithAudio(
            video=vs.video,
            original_subtitle=vs.original_subtitle,
            target_subtitle=vs.target_subtitle,
            secondary_subtitle=vs.secondary_subtitle,
            detected_language=vs.detected_language,
            audio_track=None,
            cache_hit_audio=False
        )
        for vs in video_subtitles
    )

    if progress:
        progress(1.0, "é˜¶æ®µ2è·³è¿‡: æœªå¯ç”¨è¯­éŸ³å…‹éš†")

    return results

def stage3_batch_synthesis(
        video_audios: tuple[VideoWithAudio, ...],
        video_processor: VideoProcessor,
        subtitle_writer: SubtitleWriter,
        output_dir: Path,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[ProcessedVideo, ...]:
    """é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ"""

    if progress:
        progress(0.0, "é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ")

    results = []
    total = len(video_audios)

    for idx, va in enumerate(video_audios):
        if progress:
            progress(idx / total, f"åˆæˆ: å¤„ç†è§†é¢‘ {idx + 1}/{total} - {va.video.path.name}")

        # âœ… åŒè¯­å­—å¹•ï¼šä¸­æ–‡åœ¨ä¸Šï¼Œè‹±æ–‡åœ¨ä¸‹
        bilingual = merge_bilingual_subtitles(
            va.target_subtitle,
            va.secondary_subtitle
        )

        from application.use_cases.synthesize_video_use_case import synthesize_video_use_case

        synthesis_result = synthesize_video_use_case(
            video=va.video,
            subtitles=(
                va.target_subtitle,
                va.secondary_subtitle,
                bilingual
            ),
            audio_track=va.audio_track,
            video_processor=video_processor,
            subtitle_writer=subtitle_writer,
            output_dir=output_dir,
            burn_subtitles=True,
            progress=None
        )

        processed = ProcessedVideo(
            original_video=va.video,
            subtitles=(va.target_subtitle, va.secondary_subtitle, bilingual),
            audio_tracks=(va.audio_track,) if va.audio_track else tuple(),
            output_paths=synthesis_result.output_paths
        )

        results.append(processed)
        print(f"  âœ… å®Œæˆ: {va.video.path.name}")

    if progress:
        progress(1.0, f"é˜¶æ®µ3å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    return tuple(results)


# ============== ä¸»ç”¨ä¾‹å‡½æ•° ============== #

def batch_process_use_case(
        videos: tuple[Video, ...],
        asr_provider: ASRProvider,
        translation_provider: TranslationProvider,
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        subtitle_writer: SubtitleWriter,
        cache_repo: CacheRepository,
        audio_repo: AudioFileRepository,
        output_dir: Path,
        enable_voice_cloning: bool = True,
        reference_audio_file: Path = None,
        target_language: LanguageCode = LanguageCode.CHINESE,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[ProcessedVideo, ...]:
    """
    ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†ç”¨ä¾‹ï¼ˆçº¯å‡½æ•°ï¼‰

    æŒ‰é˜¶æ®µæ‰§è¡Œï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹
    """
    if progress:
        progress(0.0, f"å¼€å§‹ä¼˜åŒ–æ‰¹é‡å¤„ç† {len(videos)} ä¸ªè§†é¢‘")

    print(f"\n{'=' * 60}")
    print(f"ğŸš€ ä¼˜åŒ–æ‰¹é‡å¤„ç†æ¨¡å¼")
    print(f"   è§†é¢‘æ•°é‡: {len(videos)}")
    print(f"   è¯­éŸ³å…‹éš†: {'å¯ç”¨' if enable_voice_cloning else 'ç¦ç”¨'}")
    print(f"{'=' * 60}\n")

    # é˜¶æ®µ1
    print(f"ğŸ“ é˜¶æ®µ1: æ‰¹é‡è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘")
    video_subtitles = stage1_batch_asr(
        videos, asr_provider, translation_provider,
        video_processor, cache_repo, target_language,
        lambda p, d: progress(p * 0.4, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ1å®Œæˆ\n")

    # é˜¶æ®µ2
    print(f"ğŸ¤ é˜¶æ®µ2: æ‰¹é‡è¯­éŸ³å…‹éš†")
    video_audios = stage2_batch_tts(
        video_subtitles, tts_provider, video_processor,
        cache_repo, audio_repo, enable_voice_cloning, reference_audio_file,
        lambda p, d: progress(0.4 + p * 0.4, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ2å®Œæˆ\n")

    # é˜¶æ®µ3
    print(f"ğŸ¬ é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ")
    results = stage3_batch_synthesis(
        video_audios, video_processor, subtitle_writer, output_dir,
        lambda p, d: progress(0.8 + p * 0.2, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ3å®Œæˆ\n")

    if progress:
        progress(1.0, "ä¼˜åŒ–æ‰¹é‡å¤„ç†å®Œæˆ")

    # ç»Ÿè®¡
    cache_hits_subtitle = sum(1 for vs in video_subtitles if vs.cache_hit_subtitle)
    cache_hits_audio = sum(1 for va in video_audios if va.cache_hit_audio)

    print(f"\n{'=' * 60}")
    print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ")
    print(f"   æ€»è§†é¢‘æ•°: {len(videos)}")
    print(f"   å­—å¹•ç¼“å­˜å‘½ä¸­: {cache_hits_subtitle}/{len(videos)}")
    if enable_voice_cloning:
        print(f"   éŸ³é¢‘ç¼“å­˜å‘½ä¸­: {cache_hits_audio}/{len(videos)}")
    print(f"   è¾“å‡ºæ–‡ä»¶æ•°: {sum(len(r.output_paths) for r in results)}")
    print(f"{'=' * 60}\n")

    return results
