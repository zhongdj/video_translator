"""
ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†ç”¨ä¾‹ - æŒ‰é˜¶æ®µæ‰§è¡Œï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹

è®¾è®¡ç†å¿µï¼š
1. é˜¶æ®µåŒ–å¤„ç†ï¼šASR -> Translation -> TTS -> Synthesis
2. æ¨¡å‹å¤ç”¨ï¼šæ¯ä¸ªé˜¶æ®µçš„æ¨¡å‹åªåŠ è½½ä¸€æ¬¡
3. å‡½æ•°å¼é£æ ¼ï¼šçº¯å‡½æ•° + ä¸å¯å˜æ•°æ®ç»“æ„
4. ç®¡é“æ¨¡å¼ï¼šæ•°æ®åœ¨é˜¶æ®µé—´æµåŠ¨

æ€§èƒ½å¯¹æ¯”ï¼š
- ä¼ ç»Ÿæ–¹å¼ï¼šNä¸ªè§†é¢‘ Ã— 3ä¸ªæ¨¡å‹ = 3Næ¬¡åŠ è½½
- ä¼˜åŒ–æ–¹å¼ï¼š3ä¸ªæ¨¡å‹å„åŠ è½½1æ¬¡ = 3æ¬¡åŠ è½½
"""
from datetime import datetime
from dataclasses import dataclass
from pathlib import Path
from typing import Optional, Callable

from domain.entities import (
    Video, Subtitle, AudioTrack, ProcessedVideo,
    LanguageCode,
)
from domain.ports import (
    ASRProvider, TranslationProvider, TTSProvider,
    VideoProcessor, SubtitleWriter, CacheRepository,
)
from domain.services import (
    merge_bilingual_subtitles,
    calculate_cache_key,
)

# ============== ä¸­é—´æ•°æ®ç»“æ„ ============== #

@dataclass(frozen=True)
class VideoWithSubtitles:
    """è§†é¢‘ + å­—å¹•çš„ä¸­é—´ç»“æœ"""
    video: Video
    original_subtitle: Subtitle
    translated_subtitle: Subtitle
    detected_language: LanguageCode
    cache_hit_subtitle: bool


@dataclass(frozen=True)
class VideoWithAudio:
    """è§†é¢‘ + å­—å¹• + éŸ³é¢‘çš„ä¸­é—´ç»“æœ"""
    video: Video
    original_subtitle: Subtitle
    translated_subtitle: Subtitle
    detected_language: LanguageCode
    audio_track: Optional[AudioTrack]
    cache_hit_audio: bool


# ============== é˜¶æ®µæ€§å¤„ç†å‡½æ•° ============== #

def stage1_batch_asr(
        videos: tuple[Video, ...],
        asr_provider: ASRProvider,
        translation_provider: TranslationProvider,
        video_processor: VideoProcessor,
        cache_repo: CacheRepository,
        target_language: LanguageCode = LanguageCode.CHINESE,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[VideoWithSubtitles, ...]:
    """
    é˜¶æ®µ1: æ‰¹é‡ ASR + ç¿»è¯‘

    å¯¹æ‰€æœ‰è§†é¢‘æ‰§è¡Œè¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘ï¼Œæ¨¡å‹åªåŠ è½½ä¸€æ¬¡
    """
    if progress:
        progress(0.0, "é˜¶æ®µ1: æ‰¹é‡è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘")

    results = []
    total = len(videos)

    for idx, video in enumerate(videos):
        video_progress = idx / total

        if progress:
            progress(video_progress, f"ASR: å¤„ç†è§†é¢‘ {idx + 1}/{total} - {video.path.name}")

        # æ£€æŸ¥ç¼“å­˜
        cache_key = calculate_cache_key(
            video.path,
            "subtitles",
            {
                "target_language": target_language.value,
                "source_language": "auto"
            }
        )

        cache_hit = cache_repo.exists(cache_key)

        if cache_hit:
            # ä»ç¼“å­˜åŠ è½½
            cached = cache_repo.get(cache_key)
            detected_lang = LanguageCode(cached["detected_language"])

            from domain.entities import TextSegment, TimeRange

            original_segments = tuple(
                TextSegment(
                    text=seg["text"],
                    time_range=TimeRange(seg["start"], seg["end"]),
                    language=detected_lang
                )
                for seg in cached.get(f"{detected_lang.value}_segments", [])
            )

            zh_segments = tuple(
                TextSegment(
                    text=seg["text"],
                    time_range=TimeRange(seg["start"], seg["end"]),
                    language=LanguageCode.CHINESE
                )
                for seg in cached.get("zh_segments", [])
            )

            original_subtitle = Subtitle(original_segments, detected_lang) if original_segments else Subtitle(zh_segments, detected_lang)
            translated_subtitle = Subtitle(zh_segments, LanguageCode.CHINESE)

            print(f"  ğŸ’¾ ç¼“å­˜å‘½ä¸­: {video.path.name}")
        else:
            # æ‰§è¡Œ ASR
            audio_path = video_processor.extract_audio(video)
            original_segments, detected_lang = asr_provider.transcribe(audio_path, None)

            # æ‰§è¡Œç¿»è¯‘
            from domain.entities import TextSegment

            en_segments = None
            zh_segments = None

            if detected_lang == LanguageCode.ENGLISH:
                en_segments = original_segments
                zh_segments = translation_provider.translate(
                    original_segments,
                    LanguageCode.ENGLISH,
                    LanguageCode.CHINESE
                )
            elif detected_lang == LanguageCode.CHINESE:
                zh_segments = original_segments
                en_segments = translation_provider.translate(
                    original_segments,
                    LanguageCode.CHINESE,
                    LanguageCode.ENGLISH
                )
            else:
                # å…¶ä»–è¯­è¨€ï¼šå…ˆç¿»è¯‘åˆ°è‹±æ–‡ï¼Œå†ç¿»è¯‘åˆ°ä¸­æ–‡
                en_segments = translation_provider.translate(
                    original_segments,
                    detected_lang,
                    LanguageCode.ENGLISH
                )
                zh_segments = translation_provider.translate(
                    en_segments,
                    LanguageCode.ENGLISH,
                    LanguageCode.CHINESE
                )

            # ä¿å­˜ç¼“å­˜
            cache_data = {
                "detected_language": detected_lang.value,
                "zh_segments": [
                    {"text": seg.text, "start": seg.time_range.start_seconds, "end": seg.time_range.end_seconds}
                    for seg in zh_segments
                ],
                "en_segments": [
                    {"text": seg.text, "start": seg.time_range.start_seconds, "end": seg.time_range.end_seconds}
                    for seg in en_segments
                ]
            }

            if detected_lang not in [LanguageCode.CHINESE, LanguageCode.ENGLISH]:
                cache_data[f"{detected_lang.value}_segments"] = [
                    {"text": seg.text, "start": seg.time_range.start_seconds, "end": seg.time_range.end_seconds}
                    for seg in original_segments
                ]

            cache_repo.set(cache_key, cache_data)

            original_subtitle = Subtitle(original_segments, detected_lang)
            translated_subtitle = Subtitle(zh_segments, LanguageCode.CHINESE)

            print(f"  âœ… å®Œæˆ: {video.path.name} ({detected_lang.value} -> zh)")

        # æ„å»ºä¸­é—´ç»“æœ
        result = VideoWithSubtitles(
            video=video,
            original_subtitle=original_subtitle,
            translated_subtitle=translated_subtitle,
            detected_language=detected_lang,
            cache_hit_subtitle=cache_hit
        )
        results.append(result)

    asr_provider.unload()
    if progress:
        progress(1.0, f"é˜¶æ®µ1å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    return tuple(results)


"""
ä¼˜åŒ–çš„ stage2_batch_tts - ä½¿ç”¨ batch_infer_same_speaker æ‰¹é‡å¤„ç† segments
"""


def stage2_batch_tts(
        video_subtitles: tuple[VideoWithSubtitles, ...],
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        cache_repo: CacheRepository,
        enable_voice_cloning: bool = True,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[VideoWithAudio, ...]:
    """
    é˜¶æ®µ2: æ‰¹é‡ TTSï¼ˆè¯­éŸ³å…‹éš†ï¼‰- ä¼˜åŒ–ç‰ˆæœ¬

    å…³é”®ä¼˜åŒ–ï¼š
    1. ä½¿ç”¨ batch_infer_same_speaker æ‰¹é‡å¤„ç†åŒä¸€è§†é¢‘çš„æ‰€æœ‰ segments
    2. ä¸€æ¬¡æ€§æå–å¹¶ç¼“å­˜è¯´è¯äººæ¡ä»¶ï¼Œé¿å…é‡å¤è®¡ç®—
    3. å‡å°‘ GPU ä¸Šä¸‹æ–‡åˆ‡æ¢ï¼Œæé«˜ååé‡

    Args:
        video_subtitles: å¸¦å­—å¹•çš„è§†é¢‘ä¸­é—´ç»“æœ
        tts_provider: TTS æä¾›è€…
        video_processor: è§†é¢‘å¤„ç†å™¨
        cache_repo: ç¼“å­˜ä»“å‚¨
        enable_voice_cloning: æ˜¯å¦å¯ç”¨è¯­éŸ³å…‹éš†
        progress: è¿›åº¦å›è°ƒ

    Returns:
        å¸¦éŸ³é¢‘çš„è§†é¢‘ä¸­é—´ç»“æœ
    """
    if progress:
        progress(0.0, "é˜¶æ®µ2: æ‰¹é‡è¯­éŸ³å…‹éš†")

    if not enable_voice_cloning:
        # è·³è¿‡è¯­éŸ³å…‹éš†ï¼Œç›´æ¥è¿”å›
        results = tuple(
            VideoWithAudio(
                video=vs.video,
                original_subtitle=vs.original_subtitle,
                translated_subtitle=vs.translated_subtitle,
                detected_language=vs.detected_language,
                audio_track=None,
                cache_hit_audio=False
            )
            for vs in video_subtitles
        )
        if progress:
            progress(1.0, "é˜¶æ®µ2è·³è¿‡: æœªå¯ç”¨è¯­éŸ³å…‹éš†")
        return results

    results = []
    total = len(video_subtitles)

    for idx, vs in enumerate(video_subtitles):
        video_progress = idx / total

        if progress:
            progress(video_progress, f"TTS: å¤„ç†è§†é¢‘ {idx + 1}/{total} - {vs.video.path.name}")

        # æ£€æŸ¥ç¼“å­˜
        cache_key = calculate_cache_key(
            vs.video.path,
            "voice_cloning",
            {
                "language": vs.translated_subtitle.language.value,
                "reference": "auto",
                "num_segments": len(vs.translated_subtitle.segments)
            }
        )

        cache_hit = cache_repo.exists(cache_key)

        if cache_hit:
            # ä»ç¼“å­˜åŠ è½½
            audio_track = _load_audio_from_cache(
                cache_repo,
                cache_key,
                vs.video.path.name,
                vs.translated_subtitle.language
            )

            if audio_track is None:
                # ç¼“å­˜æŸåï¼Œé‡æ–°ç”Ÿæˆ
                cache_hit = False

        if not cache_hit:
            # æ‰¹é‡åˆæˆéŸ³é¢‘
            audio_track = _batch_synthesize_segments(
                vs=vs,
                tts_provider=tts_provider,
                video_processor=video_processor,
                cache_repo=cache_repo,
                cache_key=cache_key
            )

            print(f"  âœ… å®Œæˆ: {vs.video.path.name} (æ‰¹é‡å¤„ç† {len(vs.translated_subtitle.segments)} ä¸ªç‰‡æ®µ)")

        # æ„å»ºä¸­é—´ç»“æœ
        result = VideoWithAudio(
            video=vs.video,
            original_subtitle=vs.original_subtitle,
            translated_subtitle=vs.translated_subtitle,
            detected_language=vs.detected_language,
            audio_track=audio_track,
            cache_hit_audio=cache_hit
        )
        results.append(result)

    if progress:
        progress(1.0, f"é˜¶æ®µ2å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    return tuple(results)


def _load_audio_from_cache(
        cache_repo: CacheRepository,
        cache_key: str,
        video_name: str,
        language: LanguageCode
) -> Optional[AudioTrack]:
    """ä»ç¼“å­˜åŠ è½½éŸ³é¢‘è½¨é“"""
    try:
        cached = cache_repo.get(cache_key)

        if cached is None or "audio_samples" not in cached or "sample_rate" not in cached:
            print(f"  âš ï¸  ç¼“å­˜æ•°æ®æŸåï¼Œé‡æ–°ç”Ÿæˆ: {video_name}")
            return None

        from domain.entities import AudioSample

        audio_sample = AudioSample(
            samples=tuple(cached["audio_samples"]),
            sample_rate=cached["sample_rate"]
        )

        audio_track = AudioTrack(audio_sample, language)

        print(f"  ğŸ’¾ ç¼“å­˜å‘½ä¸­: {video_name}")
        return audio_track

    except (KeyError, TypeError) as e:
        print(f"  âš ï¸  ç¼“å­˜æ•°æ®è§£æå¤±è´¥: {e}ï¼Œé‡æ–°ç”Ÿæˆ")
        return None


def _batch_synthesize_segments(
        vs: VideoWithSubtitles,
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        cache_repo: CacheRepository,
        cache_key: str
) -> AudioTrack:
    """
    æ‰¹é‡åˆæˆéŸ³é¢‘ç‰‡æ®µ - æ ¸å¿ƒä¼˜åŒ–é€»è¾‘

    å…³é”®æ­¥éª¤ï¼š
    1. æå–å‚è€ƒéŸ³é¢‘ï¼ˆä¸€æ¬¡æ€§ï¼‰
    2. å‡†å¤‡æ‰¹é‡æ–‡æœ¬åˆ—è¡¨
    3. è°ƒç”¨ batch_infer_same_speakerï¼ˆä¸€æ¬¡æ€§å¤„ç†æ‰€æœ‰ segmentsï¼‰
    4. å°†ç”Ÿæˆçš„éŸ³é¢‘ç‰‡æ®µæ‹¼æ¥åˆ°å®Œæ•´éŸ³é¢‘
    """
    # 1. æå–å‚è€ƒéŸ³é¢‘
    reference_audio_path = video_processor.extract_reference_audio(
        vs.video,
        duration=10.0
    )

    # 2. å‡†å¤‡æ‰¹é‡æ–‡æœ¬
    segments = vs.translated_subtitle.segments
    texts = [segment.text for segment in segments]

    print(f"  ğŸ¤ æ‰¹é‡åˆæˆ: {len(texts)} ä¸ªç‰‡æ®µ")

    # 3. è°ƒç”¨æ‰¹é‡æ¨ç†ï¼ˆæ ¸å¿ƒä¼˜åŒ–ç‚¹ï¼‰
    synthesized_audios = tts_provider.batch_synthesize(
        texts=texts,
        reference_audio_path=reference_audio_path,
        language=vs.translated_subtitle.language
    )

    # 4. æ„å»ºå®Œæ•´éŸ³é¢‘è½¨é“
    audio_track = _assemble_full_audio(
        synthesized_audios=synthesized_audios,
        segments=segments,
        video_duration=vs.video.duration,
        language=vs.translated_subtitle.language
    )

    # 5. ä¿å­˜ç¼“å­˜
    _save_audio_to_cache(
        cache_repo=cache_repo,
        cache_key=cache_key,
        audio_track=audio_track,
        reference_audio_path=reference_audio_path
    )

    return audio_track


def _assemble_full_audio(
        synthesized_audios: tuple,
        segments: tuple,
        video_duration: float,
        language: LanguageCode
) -> AudioTrack:
    """
    å°†æ‰¹é‡åˆæˆçš„éŸ³é¢‘ç‰‡æ®µæ‹¼æ¥æˆå®Œæ•´éŸ³é¢‘

    Args:
        synthesized_audios: batch_synthesize è¿”å›çš„éŸ³é¢‘åˆ—è¡¨
        segments: å¯¹åº”çš„å­—å¹•ç‰‡æ®µ
        video_duration: è§†é¢‘æ€»æ—¶é•¿
        language: ç›®æ ‡è¯­è¨€

    Returns:
        å®Œæ•´çš„éŸ³é¢‘è½¨é“
    """
    from domain.entities import AudioSample

    # è·å–é‡‡æ ·ç‡ï¼ˆå‡è®¾æ‰€æœ‰ç‰‡æ®µé‡‡æ ·ç‡ç›¸åŒï¼‰
    sample_rate = synthesized_audios[0].sample_rate

    # åˆå§‹åŒ–å®Œæ•´éŸ³é¢‘æ•°ç»„
    total_samples = int(video_duration * sample_rate)
    full_audio_list = [0.0] * total_samples

    # æŒ‰æ—¶é—´è½´æ”¾ç½®æ¯ä¸ªéŸ³é¢‘ç‰‡æ®µ
    for audio_sample, segment in zip(synthesized_audios, segments):
        start_idx = int(segment.time_range.start_seconds * sample_rate)

        # å¤åˆ¶éŸ³é¢‘æ•°æ®åˆ°å¯¹åº”ä½ç½®
        for i, sample in enumerate(audio_sample.samples):
            target_idx = start_idx + i
            if target_idx < total_samples:
                full_audio_list[target_idx] = sample

    # æ„å»ºå®Œæ•´éŸ³é¢‘
    full_audio = AudioSample(
        samples=tuple(full_audio_list),
        sample_rate=sample_rate
    )

    return AudioTrack(full_audio, language)


def _save_audio_to_cache(
        cache_repo: CacheRepository,
        cache_key: str,
        audio_track: AudioTrack,
        reference_audio_path: Path
) -> None:
    """ä¿å­˜éŸ³é¢‘åˆ°ç¼“å­˜"""
    cache_data = {
        "audio_samples": list(audio_track.audio.samples),
        "sample_rate": audio_track.audio.sample_rate,
        "reference_audio": str(reference_audio_path),
        "reference_duration": 10.0
    }
    cache_repo.set(cache_key, cache_data)


def stage3_batch_synthesis(
        video_audios: tuple[VideoWithAudio, ...],
        video_processor: VideoProcessor,
        subtitle_writer: SubtitleWriter,
        cache_repo: CacheRepository,  # æ–°å¢ç¼“å­˜ä»“å‚¨å‚æ•°
        output_dir: Path,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[ProcessedVideo, ...]:
    """
    é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆï¼ˆå¸¦ç¼“å­˜å’Œæ–­ç‚¹ç»­ä¼ ï¼‰

    ä¸ºæ‰€æœ‰è§†é¢‘ç”Ÿæˆå­—å¹•æ–‡ä»¶å’Œæœ€ç»ˆè§†é¢‘ï¼Œæ”¯æŒæ–­ç‚¹ç»­ä¼ 
    """
    if progress:
        progress(0.0, "é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ")

    results = []
    total = len(video_audios)

    for idx, va in enumerate(video_audios):
        video_progress = idx / total

        if progress:
            progress(video_progress, f"åˆæˆ: å¤„ç†è§†é¢‘ {idx + 1}/{total} - {va.video.path.name}")

        # æ£€æŸ¥è§†é¢‘åˆæˆç¼“å­˜
        cache_key = calculate_cache_key(
            va.video.path,
            "video_synthesis",
            {
                "subtitles_hash": hash((va.original_subtitle, va.translated_subtitle)),
                "audio_track_hash": hash(va.audio_track) if va.audio_track else "no_audio",
                "output_dir": str(output_dir)
            }
        )

        cache_hit = cache_repo.exists(cache_key)
        processed_video = None

        if cache_hit:
            # å°è¯•ä»ç¼“å­˜åŠ è½½å·²å¤„ç†çš„è§†é¢‘ä¿¡æ¯
            try:
                cached_data = cache_repo.get(cache_key)
                if cached_data and _validate_cached_video(cached_data, output_dir):
                    processed_video = _load_processed_video_from_cache(cached_data, va)
                    print(f"  ğŸ’¾ è§†é¢‘åˆæˆç¼“å­˜å‘½ä¸­: {va.video.path.name}")
            except (KeyError, ValueError, FileNotFoundError) as e:
                print(f"  âš ï¸  è§†é¢‘åˆæˆç¼“å­˜æŸå: {e}ï¼Œé‡æ–°ç”Ÿæˆ")
                cache_hit = False

        if not cache_hit:
            # åˆ›å»ºåŒè¯­å­—å¹•
            bilingual = merge_bilingual_subtitles(
                va.translated_subtitle,
                va.original_subtitle
            )

            # æ‰§è¡Œè§†é¢‘åˆæˆ
            from application.use_cases.synthesize_video_use_case import synthesize_video_use_case

            synthesis_result = synthesize_video_use_case(
                video=va.video,
                subtitles=(
                    va.translated_subtitle,
                    va.original_subtitle,
                    bilingual
                ),
                audio_track=va.audio_track,
                video_processor=video_processor,
                subtitle_writer=subtitle_writer,
                output_dir=output_dir,
                burn_subtitles=True,
                progress=None  # ä¸ä¼ é€’è¿›åº¦ï¼Œé¿å…è¿‡å¤šè¾“å‡º
            )

            # æ„å»ºç»“æœ
            processed_video = ProcessedVideo(
                original_video=va.video,
                subtitles=(
                    va.translated_subtitle,
                    va.original_subtitle,
                    bilingual
                ),
                audio_tracks=(va.audio_track,) if va.audio_track else tuple(),
                output_paths=synthesis_result.output_paths
            )

            # ä¿å­˜è§†é¢‘åˆæˆç¼“å­˜
            _save_video_synthesis_cache(
                cache_repo=cache_repo,
                cache_key=cache_key,
                processed_video=processed_video,
                output_dir=output_dir
            )

            print(f"  âœ… å®Œæˆ: {va.video.path.name}")

        results.append(processed_video)

    if progress:
        progress(1.0, f"é˜¶æ®µ3å®Œæˆ: å¤„ç†äº† {total} ä¸ªè§†é¢‘")

    return tuple(results)


def _validate_cached_video(cached_data: dict, output_dir: Path) -> bool:
    """
    éªŒè¯ç¼“å­˜çš„è§†é¢‘æ–‡ä»¶æ˜¯å¦æœ‰æ•ˆ

    Args:
        cached_data: ç¼“å­˜æ•°æ®
        output_dir: è¾“å‡ºç›®å½•

    Returns:
        bool: ç¼“å­˜æ˜¯å¦æœ‰æ•ˆ
    """
    try:
        output_paths = cached_data.get("output_paths", [])
        if not output_paths:
            return False

        for path_str in output_paths:
            output_path = Path(path_str)
            # æ£€æŸ¥æ–‡ä»¶æ˜¯å¦å­˜åœ¨ä¸”å¤§å°åˆç†ï¼ˆè‡³å°‘1KBï¼‰
            if not output_path.exists() or output_path.stat().st_size < 1024:
                return False

        return True
    except (KeyError, OSError):
        return False


def _load_processed_video_from_cache(cached_data: dict, va: VideoWithAudio) -> ProcessedVideo:
    """
    ä»ç¼“å­˜åŠ è½½å·²å¤„ç†çš„è§†é¢‘ä¿¡æ¯

    Args:
        cached_data: ç¼“å­˜æ•°æ®
        va: è§†é¢‘éŸ³é¢‘ä¸­é—´ç»“æœ

    Returns:
        ProcessedVideo: å¤„ç†åçš„è§†é¢‘
    """
    output_paths = tuple(Path(path_str) for path_str in cached_data["output_paths"])

    return ProcessedVideo(
        original_video=va.video,
        subtitles=(
            va.translated_subtitle,
            va.original_subtitle,
            merge_bilingual_subtitles(va.translated_subtitle, va.original_subtitle)
        ),
        audio_tracks=(va.audio_track,) if va.audio_track else tuple(),
        output_paths=output_paths
    )


def _save_video_synthesis_cache(
        cache_repo: CacheRepository,
        cache_key: str,
        processed_video: ProcessedVideo,
        output_dir: Path
) -> None:
    """
    ä¿å­˜è§†é¢‘åˆæˆç¼“å­˜

    Args:
        cache_repo: ç¼“å­˜ä»“å‚¨
        cache_key: ç¼“å­˜é”®
        processed_video: å¤„ç†åçš„è§†é¢‘
        output_dir: è¾“å‡ºç›®å½•
    """
    cache_data = {
        "output_paths": [str(path) for path in processed_video.output_paths],
        "original_video": str(processed_video.original_video.path),
        "timestamp": datetime.now().isoformat()
    }

    cache_repo.set(cache_key, cache_data)


# ============== ä¸»ç”¨ä¾‹å‡½æ•° ============== #

def batch_process_use_case(
        videos: tuple[Video, ...],
        asr_provider: ASRProvider,
        translation_provider: TranslationProvider,
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        subtitle_writer: SubtitleWriter,
        cache_repo: CacheRepository,
        output_dir: Path,
        enable_voice_cloning: bool = True,
        target_language: LanguageCode = LanguageCode.CHINESE,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[ProcessedVideo, ...]:
    """
    ä¼˜åŒ–çš„æ‰¹é‡å¤„ç†ç”¨ä¾‹ï¼ˆçº¯å‡½æ•°ï¼‰

    æŒ‰é˜¶æ®µæ‰§è¡Œï¼Œé¿å…é‡å¤åŠ è½½æ¨¡å‹ï¼š
    1. é˜¶æ®µ1: æ‰¹é‡ ASR + ç¿»è¯‘ï¼ˆæ‰€æœ‰è§†é¢‘ï¼‰
    2. é˜¶æ®µ2: æ‰¹é‡ TTSï¼ˆæ‰€æœ‰è§†é¢‘ï¼‰
    3. é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆï¼ˆæ‰€æœ‰è§†é¢‘ï¼‰

    æ€§èƒ½æå‡ï¼š
    - ä¼ ç»Ÿæ–¹å¼ï¼š3N æ¬¡æ¨¡å‹åŠ è½½ï¼ˆN = è§†é¢‘æ•°é‡ï¼‰
    - ä¼˜åŒ–æ–¹å¼ï¼š3 æ¬¡æ¨¡å‹åŠ è½½ï¼ˆæ¯ç§æ¨¡å‹åŠ è½½1æ¬¡ï¼‰

    Args:
        videos: å¾…å¤„ç†çš„è§†é¢‘åˆ—è¡¨
        asr_provider: ASR æä¾›è€…
        translation_provider: ç¿»è¯‘æä¾›è€…
        tts_provider: TTS æä¾›è€…
        video_processor: è§†é¢‘å¤„ç†å™¨
        subtitle_writer: å­—å¹•å†™å…¥å™¨
        cache_repo: ç¼“å­˜ä»“å‚¨
        output_dir: è¾“å‡ºç›®å½•
        enable_voice_cloning: æ˜¯å¦å¯ç”¨è¯­éŸ³å…‹éš†
        target_language: ç›®æ ‡è¯­è¨€
        progress: è¿›åº¦å›è°ƒ

    Returns:
        å¤„ç†ç»“æœåˆ—è¡¨
    """
    if progress:
        progress(0.0, f"å¼€å§‹ä¼˜åŒ–æ‰¹é‡å¤„ç† {len(videos)} ä¸ªè§†é¢‘")

    print(f"\n{'='*60}")
    print(f"ğŸš€ ä¼˜åŒ–æ‰¹é‡å¤„ç†æ¨¡å¼")
    print(f"   è§†é¢‘æ•°é‡: {len(videos)}")
    print(f"   è¯­éŸ³å…‹éš†: {'å¯ç”¨' if enable_voice_cloning else 'ç¦ç”¨'}")
    print(f"{'='*60}\n")

    # é˜¶æ®µ1: æ‰¹é‡ ASR + ç¿»è¯‘
    print(f"ğŸ“ é˜¶æ®µ1: æ‰¹é‡è¯­éŸ³è¯†åˆ«å’Œç¿»è¯‘")
    video_subtitles = stage1_batch_asr(
        videos=videos,
        asr_provider=asr_provider,
        translation_provider=translation_provider,
        video_processor=video_processor,
        cache_repo=cache_repo,
        target_language=target_language,
        progress=lambda p, d: progress(p * 0.4, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ1å®Œæˆ\n")

    # é˜¶æ®µ2: æ‰¹é‡ TTS
    print(f"ğŸ¤ é˜¶æ®µ2: æ‰¹é‡è¯­éŸ³å…‹éš†")
    video_audios = stage2_batch_tts(
        video_subtitles=video_subtitles,
        tts_provider=tts_provider,
        video_processor=video_processor,
        cache_repo=cache_repo,
        enable_voice_cloning=enable_voice_cloning,
        progress=lambda p, d: progress(0.4 + p * 0.4, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ2å®Œæˆ\n")

    # é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ
    print(f"ğŸ¬ é˜¶æ®µ3: æ‰¹é‡è§†é¢‘åˆæˆ")
    results = stage3_batch_synthesis(
        video_audios=video_audios,
        video_processor=video_processor,
        subtitle_writer=subtitle_writer,
        cache_repo=cache_repo,  # æ–°å¢å‚æ•°
        output_dir=output_dir,
        progress=lambda p, d: progress(0.8 + p * 0.2, d) if progress else None
    )
    print(f"âœ… é˜¶æ®µ3å®Œæˆ\n")

    if progress:
        progress(1.0, "ä¼˜åŒ–æ‰¹é‡å¤„ç†å®Œæˆ")

    # ç»Ÿè®¡ä¿¡æ¯
    cache_hits_subtitle = sum(1 for vs in video_subtitles if vs.cache_hit_subtitle)
    cache_hits_audio = sum(1 for va in video_audios if va.cache_hit_audio)

    print(f"\n{'='*60}")
    print(f"âœ… æ‰¹é‡å¤„ç†å®Œæˆ")
    print(f"   æ€»è§†é¢‘æ•°: {len(videos)}")
    print(f"   å­—å¹•ç¼“å­˜å‘½ä¸­: {cache_hits_subtitle}/{len(videos)}")
    if enable_voice_cloning:
        print(f"   éŸ³é¢‘ç¼“å­˜å‘½ä¸­: {cache_hits_audio}/{len(videos)}")
    print(f"   è¾“å‡ºæ–‡ä»¶æ•°: {sum(len(r.output_paths) for r in results)}")
    print(f"{'='*60}\n")

    return results