"""
è¯­éŸ³å…‹éš†ç”¨ä¾‹ - ä¿®å¤ç¼“å­˜éªŒè¯é—®é¢˜
"""

from application import *

# å¯¼å…¥é¢†åŸŸå±‚
from domain.entities import (
    Video, Subtitle, AudioTrack, VoiceProfile,
    AudioSample,
)

from domain.ports import (
    TTSProvider,
    VideoProcessor, CacheRepository,
)

from domain.services import (
    calculate_cache_key,
)


def validate_voice_cache(cached):
    """éªŒè¯è¯­éŸ³ç¼“å­˜æ•°æ®çš„å®Œæ•´æ€§"""
    if cached is None:
        return False

    required_keys = ["audio_samples", "sample_rate", "reference_audio", "reference_duration"]

    for key in required_keys:
        if key not in cached:
            return False

    if not isinstance(cached["audio_samples"], (list, tuple)):
        return False

    if not isinstance(cached["sample_rate"], int):
        return False

    if len(cached["audio_samples"]) == 0:
        return False

    return True


def clone_voice_use_case(
        video: Video,
        subtitle: Subtitle,
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        cache_repo: CacheRepository,
        reference_audio_path: Optional[Path] = None,
        reference_duration: float = 10.0,
        progress: ProgressCallback = None
) -> VoiceCloningResult:
    """
    è¯­éŸ³å…‹éš†ç”¨ä¾‹ï¼ˆçº¯å‡½æ•°ï¼‰- ä¿®å¤ç‰ˆ

    æµç¨‹:
    1. æ£€æŸ¥ç¼“å­˜ï¼ˆå¸¦éªŒè¯ï¼‰
    2. æå–/ä½¿ç”¨å‚è€ƒéŸ³é¢‘
    3. åˆ›å»ºå£°éŸ³é…ç½®
    4. é€å¥åˆæˆ
    5. æ‹¼æ¥éŸ³é¢‘
    """
    if progress:
        progress(0.0, "å¼€å§‹è¯­éŸ³å…‹éš†")

    # 1. æ£€æŸ¥ç¼“å­˜ï¼ˆå¸¦å®Œæ•´æ€§éªŒè¯ï¼‰
    cache_key = calculate_cache_key(
        video.path,
        "voice_cloning",
        {
            "language": subtitle.language.value,
            "reference": str(reference_audio_path) if reference_audio_path else "auto",
            "num_segments": len(subtitle.segments)
        }
    )

    cache_hit = False

    if cache_repo.exists(cache_key):
        cached = cache_repo.get(cache_key)

        # éªŒè¯ç¼“å­˜æ•°æ®å®Œæ•´æ€§
        if validate_voice_cache(cached):
            try:
                audio_sample = AudioSample(
                    samples=tuple(cached["audio_samples"]),
                    sample_rate=cached["sample_rate"]
                )

                voice_profile = VoiceProfile(
                    reference_audio_path=Path(cached["reference_audio"]),
                    language=subtitle.language,
                    duration=cached["reference_duration"]
                )

                if progress:
                    progress(1.0, "è¯­éŸ³å…‹éš†ç¼“å­˜å‘½ä¸­")

                print(f"ğŸ’¾ è¯­éŸ³å…‹éš†ç¼“å­˜å‘½ä¸­: {video.path.name}")

                return VoiceCloningResult(
                    audio_track=AudioTrack(audio_sample, subtitle.language),
                    voice_profile=voice_profile,
                    total_segments=len(subtitle.segments),
                    cache_hit=True
                )
            except Exception as e:
                print(f"âš ï¸  ç¼“å­˜æ•°æ®è§£æå¤±è´¥: {e}ï¼Œå°†é‡æ–°ç”Ÿæˆ")
                cache_hit = False
        else:
            print(f"âš ï¸  ç¼“å­˜æ•°æ®æŸåï¼Œå°†é‡æ–°ç”Ÿæˆ")
            cache_hit = False

    # 2. æå–æˆ–ä½¿ç”¨å‚è€ƒéŸ³é¢‘
    if progress:
        progress(0.1, "å‡†å¤‡å‚è€ƒéŸ³é¢‘")

    if reference_audio_path is None:
        reference_audio_path = video_processor.extract_reference_audio(
            video,
            reference_duration
        )

    # 3. åˆ›å»ºå£°éŸ³é…ç½®
    voice_profile = VoiceProfile(
        reference_audio_path=reference_audio_path,
        language=subtitle.language,
        duration=reference_duration
    )

    # 4. é€å¥åˆæˆ
    if progress:
        progress(0.2, "åˆæˆè¯­éŸ³")

    synthesized_segments = []
    total_segments = len(subtitle.segments)

    for idx, segment in enumerate(subtitle.segments):
        if progress:
            prog = 0.2 + (idx / total_segments) * 0.7
            progress(prog, f"åˆæˆè¯­éŸ³ {idx + 1}/{total_segments}")

        # åˆæˆå•ä¸ªç‰‡æ®µ
        try:
            audio_sample = tts_provider.synthesize(
                text=segment.text,
                voice_profile=voice_profile,
                target_duration=segment.time_range.duration
            )

            synthesized_segments.append((audio_sample, segment))
        except Exception as e:
            print(f"âŒ ç‰‡æ®µ {idx} åˆæˆå¤±è´¥: {e}")
            # ä½¿ç”¨é™éŸ³ä»£æ›¿
            silent_samples = int(22050 * segment.time_range.duration)
            silent_audio = AudioSample(
                samples=tuple([0.0] * silent_samples),
                sample_rate=22050
            )
            synthesized_segments.append((silent_audio, segment))

    # 5. æ‹¼æ¥éŸ³é¢‘ï¼ˆåˆ›å»ºå®Œæ•´éŸ³è½¨ï¼‰
    if progress:
        progress(0.9, "æ‹¼æ¥éŸ³é¢‘")

    # è®¡ç®—æ€»æ ·æœ¬æ•°
    total_samples = int(video.duration * synthesized_segments[0][0].sample_rate)
    full_audio_list = [0.0] * total_samples

    # å¡«å……å„ä¸ªç‰‡æ®µ
    for audio_sample, segment in synthesized_segments:
        start_idx = int(segment.time_range.start_seconds * audio_sample.sample_rate)
        for i, sample in enumerate(audio_sample.samples):
            if start_idx + i < total_samples:
                full_audio_list[start_idx + i] = sample

    full_audio = AudioSample(
        samples=tuple(full_audio_list),
        sample_rate=synthesized_segments[0][0].sample_rate
    )

    # ä¿å­˜ç¼“å­˜ï¼ˆå¸¦å®Œæ•´æ•°æ®ï¼‰
    try:
        cache_data = {
            "audio_samples": list(full_audio.samples),
            "sample_rate": full_audio.sample_rate,
            "reference_audio": str(reference_audio_path),
            "reference_duration": reference_duration
        }

        # å†æ¬¡éªŒè¯è¦ä¿å­˜çš„æ•°æ®
        if validate_voice_cache(cache_data):
            cache_repo.set(cache_key, cache_data)
            print(f"âœ… è¯­éŸ³ç¼“å­˜å·²ä¿å­˜")
        else:
            print(f"âš ï¸  ç¼“å­˜æ•°æ®éªŒè¯å¤±è´¥ï¼Œè·³è¿‡ä¿å­˜")
    except Exception as e:
        print(f"âš ï¸  ä¿å­˜ç¼“å­˜å¤±è´¥: {e}")

    if progress:
        progress(1.0, "è¯­éŸ³å…‹éš†å®Œæˆ")

    return VoiceCloningResult(
        audio_track=AudioTrack(full_audio, subtitle.language),
        voice_profile=voice_profile,
        total_segments=len(subtitle.segments),
        cache_hit=False
    )