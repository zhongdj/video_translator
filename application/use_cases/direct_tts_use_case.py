"""
Application Layer - ç›´æ¥æ–‡æœ¬è½¬è¯­éŸ³ç”¨ä¾‹
ç»™å®šæ–‡æœ¬å’Œå‚è€ƒéŸ³é¢‘ï¼Œç›´æ¥åˆæˆè¯­éŸ³
"""
import time
from pathlib import Path
from typing import Optional, Callable
from dataclasses import dataclass

from domain.entities import VoiceProfile, AudioSample
from domain.value_objects import LanguageCode
from domain.ports import TTSProvider


@dataclass(frozen=True)
class DirectTTSResult:
    """ç›´æ¥TTSç»“æœ"""
    audio_sample: AudioSample
    text: str
    reference_audio_path: Path
    synthesis_time: float
    language: LanguageCode


def direct_tts_use_case(
        text: str,
        reference_audio_path: Path,
        tts_provider: TTSProvider,
        language: LanguageCode = LanguageCode.CHINESE,
        target_duration: Optional[float] = None,
        reference_duration: float = 10.0,
        progress: Optional[Callable[[float, str], None]] = None
) -> DirectTTSResult:
    """
    ç›´æ¥æ–‡æœ¬è½¬è¯­éŸ³ç”¨ä¾‹ï¼ˆçº¯å‡½æ•°ï¼‰

    Args:
        text: è¦åˆæˆçš„æ–‡æœ¬
        reference_audio_path: å‚è€ƒéŸ³é¢‘è·¯å¾„
        tts_provider: TTSæä¾›è€…
        language: ç›®æ ‡è¯­è¨€
        target_duration: ç›®æ ‡æ—¶é•¿ï¼ˆç§’ï¼‰ï¼Œå¯é€‰
        reference_duration: å‚è€ƒéŸ³é¢‘æ—¶é•¿ï¼ˆç§’ï¼‰
        progress: è¿›åº¦å›è°ƒ

    Returns:
        DirectTTSResult: åŒ…å«åˆæˆçš„éŸ³é¢‘å’Œå…ƒæ•°æ®
    """
    start_time = time.perf_counter()

    if progress:
        progress(0.0, "å‡†å¤‡åˆæˆ...")

    # éªŒè¯è¾“å…¥
    if not text or not text.strip():
        raise ValueError("æ–‡æœ¬ä¸èƒ½ä¸ºç©º")

    if not reference_audio_path.exists():
        raise FileNotFoundError(f"å‚è€ƒéŸ³é¢‘ä¸å­˜åœ¨: {reference_audio_path}")

    # åˆ›å»ºè¯­éŸ³é…ç½®
    if progress:
        progress(0.2, "åˆ›å»ºè¯­éŸ³é…ç½®...")

    voice_profile = VoiceProfile(
        reference_audio_path=reference_audio_path,
        language=language,
        duration=reference_duration
    )

    # æ‰§è¡Œåˆæˆ
    if progress:
        progress(0.4, f"åˆæˆè¯­éŸ³: {len(text)} å­—ç¬¦...")

    audio_sample = tts_provider.synthesize(
        text=text,
        voice_profile=voice_profile,
        target_duration=target_duration
    )

    synthesis_time = time.perf_counter() - start_time

    if progress:
        progress(1.0, "åˆæˆå®Œæˆ")

    return DirectTTSResult(
        audio_sample=audio_sample,
        text=text,
        reference_audio_path=reference_audio_path,
        synthesis_time=synthesis_time,
        language=language
    )


def batch_direct_tts_use_case(
        texts: list[str],
        reference_audio_path: Path,
        tts_provider: TTSProvider,
        language: LanguageCode = LanguageCode.CHINESE,
        target_durations: Optional[list[float]] = None,
        reference_duration: float = 10.0,
        progress: Optional[Callable[[float, str], None]] = None
) -> tuple[DirectTTSResult, ...]:
    """
    æ‰¹é‡æ–‡æœ¬è½¬è¯­éŸ³ç”¨ä¾‹

    Args:
        texts: æ–‡æœ¬åˆ—è¡¨
        reference_audio_path: å‚è€ƒéŸ³é¢‘è·¯å¾„
        tts_provider: TTSæä¾›è€…
        language: ç›®æ ‡è¯­è¨€
        target_durations: ç›®æ ‡æ—¶é•¿åˆ—è¡¨ï¼ˆå¯é€‰ï¼‰
        reference_duration: å‚è€ƒéŸ³é¢‘æ—¶é•¿
        progress: è¿›åº¦å›è°ƒ

    Returns:
        DirectTTSResultå…ƒç»„
    """
    start_time = time.perf_counter()

    if progress:
        progress(0.0, f"æ‰¹é‡åˆæˆ {len(texts)} æ®µæ–‡æœ¬...")

    if not reference_audio_path.exists():
        raise FileNotFoundError(f"å‚è€ƒéŸ³é¢‘ä¸å­˜åœ¨: {reference_audio_path}")

    if target_durations and len(target_durations) != len(texts):
        raise ValueError("target_durationsé•¿åº¦å¿…é¡»ä¸textsä¸€è‡´")

    # æ‰¹é‡åˆæˆ
    if progress:
        progress(0.2, "æ‰§è¡Œæ‰¹é‡åˆæˆ...")

    audio_samples = tts_provider.batch_synthesize(
        texts=texts,
        reference_audio_path=reference_audio_path,
        language=language,
        target_durations=target_durations
    )

    synthesis_time = time.perf_counter() - start_time

    # æ„å»ºç»“æœ
    results = []
    for idx, (text, audio_sample) in enumerate(zip(texts, audio_samples)):
        result = DirectTTSResult(
            audio_sample=audio_sample,
            text=text,
            reference_audio_path=reference_audio_path,
            synthesis_time=synthesis_time / len(texts),
            language=language
        )
        results.append(result)

        if progress:
            progress(0.2 + (idx + 1) / len(texts) * 0.8, f"å®Œæˆ {idx + 1}/{len(texts)}")

    if progress:
        progress(1.0, f"æ‰¹é‡åˆæˆå®Œæˆï¼Œè€—æ—¶ {synthesis_time:.1f}ç§’")

    return tuple(results)


# ============== è¾…åŠ©å‡½æ•°ï¼šä¿å­˜éŸ³é¢‘ ============== #

def save_audio_to_file(
        audio_sample: AudioSample,
        output_path: Path,
        format: str = "wav"
) -> Path:
    """
    ä¿å­˜éŸ³é¢‘åˆ°æ–‡ä»¶

    Args:
        audio_sample: éŸ³é¢‘æ ·æœ¬
        output_path: è¾“å‡ºè·¯å¾„
        format: éŸ³é¢‘æ ¼å¼ï¼ˆwav/mp3ï¼‰

    Returns:
        ä¿å­˜çš„æ–‡ä»¶è·¯å¾„
    """
    import numpy as np
    import soundfile as sf

    # âœ… ç¡®ä¿çˆ¶ç›®å½•å­˜åœ¨
    output_path.parent.mkdir(parents=True, exist_ok=True)

    # âœ… ä½¿ç”¨ç»å¯¹è·¯å¾„
    output_path = output_path.resolve()

    # è½¬æ¢ä¸ºnumpyæ•°ç»„
    audio_data = np.array(audio_sample.samples, dtype=np.float32)

    # ä¿å­˜æ–‡ä»¶
    if format.lower() == "wav":
        sf.write(
            str(output_path),
            audio_data,
            audio_sample.sample_rate,
            format='WAV',
            subtype='PCM_16'  # âœ… æ˜ç¡®æŒ‡å®šå­ç±»å‹
        )
        print(f"âœ… WAV å·²ä¿å­˜: {output_path}")

    elif format.lower() == "mp3":
        # éœ€è¦å®‰è£… pydub å’Œ ffmpeg
        try:
            from pydub import AudioSegment

            # âœ… å…ˆä¿å­˜ä¸ºä¸´æ—¶WAVï¼ˆä½¿ç”¨ç»å¯¹è·¯å¾„ï¼‰
            temp_wav = output_path.parent / f"temp_{output_path.stem}.wav"
            sf.write(str(temp_wav), audio_data, audio_sample.sample_rate, subtype='PCM_16')

            # âœ… éªŒè¯ä¸´æ—¶æ–‡ä»¶
            if not temp_wav.exists():
                raise FileNotFoundError(f"ä¸´æ—¶ WAV æ–‡ä»¶åˆ›å»ºå¤±è´¥: {temp_wav}")

            print(f"ğŸ“ ä¸´æ—¶ WAV: {temp_wav} ({temp_wav.stat().st_size} bytes)")

            # è½¬æ¢ä¸ºMP3
            audio = AudioSegment.from_wav(str(temp_wav))
            audio.export(str(output_path), format="mp3", bitrate="192k")

            print(f"âœ… MP3 å·²ä¿å­˜: {output_path}")

            # åˆ é™¤ä¸´æ—¶æ–‡ä»¶
            if temp_wav.exists():
                temp_wav.unlink()
                print(f"ğŸ—‘ï¸  åˆ é™¤ä¸´æ—¶æ–‡ä»¶: {temp_wav}")

        except ImportError as e:
            print(f"âš ï¸  MP3 è½¬æ¢å¤±è´¥: {e}")
            print("   è¯·å®‰è£…: pip install pydub")
            print("   å¹¶ç¡®ä¿å®‰è£…äº† ffmpeg")
            # âœ… é™çº§ä¸º WAV æ ¼å¼
            wav_path = output_path.with_suffix('.wav')
            sf.write(str(wav_path), audio_data, audio_sample.sample_rate, subtype='PCM_16')
            print(f"âœ… é™çº§ä¸º WAV: {wav_path}")
            return wav_path

        except Exception as e:
            print(f"âŒ MP3 è½¬æ¢é”™è¯¯: {e}")
            # æ¸…ç†å¯èƒ½å­˜åœ¨çš„ä¸´æ—¶æ–‡ä»¶
            temp_wav = output_path.parent / f"temp_{output_path.stem}.wav"
            if temp_wav.exists():
                temp_wav.unlink()
            raise
    else:
        raise ValueError(f"ä¸æ”¯æŒçš„æ ¼å¼: {format}")

    # âœ… éªŒè¯æœ€ç»ˆæ–‡ä»¶æ˜¯å¦å­˜åœ¨
    if not output_path.exists():
        raise FileNotFoundError(f"æ–‡ä»¶ä¿å­˜å¤±è´¥: {output_path}")

    return output_path