"""
Application Layer - å¤šè¯´è¯äººè¯­éŸ³å…‹éš†ç”¨ä¾‹
"""
import time
from pathlib import Path
from typing import Optional, Callable, Dict

from domain.entities import (
    Video, Subtitle, AudioSegment, IncrementalSynthesisResult,
    AudioSample, AudioTrack
)
from domain.multi_speaker import (
    MultiSpeakerConfig, SpeakerId, MultiSpeakerVoiceProfile
)
from domain.ports import (
    TTSProvider, VideoProcessor,
    CacheRepository, AudioSegmentRepository
)


def _get_segment_cache_key_multi(
        video_path: Path,
        segment_index: int,
        text: str,
        speaker_id: str
) -> str:
    """ç”Ÿæˆå¤šè¯´è¯äººç‰‡æ®µç¼“å­˜é”®"""
    import hashlib
    content = f"{video_path.name}_{segment_index}_{text}_{speaker_id}"
    return hashlib.md5(content.encode()).hexdigest()[:16]


def _synthesize_segment_with_speaker(
        text_seg,
        segment_index: int,
        voice_profile: MultiSpeakerVoiceProfile,
        tts_provider: TTSProvider,
        video: Video,
        audio_repo: AudioSegmentRepository
) -> AudioSegment:
    """ä½¿ç”¨æŒ‡å®šè¯´è¯äººåˆæˆå•ä¸ªç‰‡æ®µ"""
    from domain.entities import VoiceProfile

    # è½¬æ¢ä¸ºå•è¯´è¯äºº VoiceProfileï¼ˆé€‚é…ç°æœ‰ TTS æ¥å£ï¼‰
    single_voice_profile = VoiceProfile(
        reference_audio_path=voice_profile.reference_audio_path,
        language=voice_profile.language,
        duration=voice_profile.duration
    )

    # åˆæˆéŸ³é¢‘
    audio_sample = tts_provider.synthesize(
        text=text_seg.text,
        voice_profile=single_voice_profile,
        target_duration=text_seg.time_range.duration
    )

    # åˆ›å»ºç¼“å­˜é”®
    cache_key = _get_segment_cache_key_multi(
        video.path,
        segment_index,
        text_seg.text,
        voice_profile.speaker_id.id
    )

    # åˆ›å»ºéŸ³é¢‘ç‰‡æ®µå®ä½“
    audio_seg = AudioSegment(
        segment_index=segment_index,
        audio=audio_sample,
        text_segment=text_seg,
        cache_key=cache_key
    )

    # ä¿å­˜åˆ°ä»“å‚¨
    file_path = audio_repo.save_segment(segment_index, audio_seg, video.path)
    return audio_seg.with_file_path(file_path)


def multi_speaker_voice_cloning_use_case(
        video: Video,
        subtitle: Subtitle,
        multi_speaker_config: MultiSpeakerConfig,
        tts_provider: TTSProvider,
        video_processor: VideoProcessor,
        audio_repo: AudioSegmentRepository,
        cache_repo: CacheRepository,
        progress: Optional[Callable[[float, str, int, Optional[AudioSegment]], None]] = None
) -> IncrementalSynthesisResult:
    """
    å¤šè¯´è¯äººè¯­éŸ³å…‹éš†ç”¨ä¾‹

    Args:
        video: è§†é¢‘å¯¹è±¡
        subtitle: å­—å¹•å¯¹è±¡
        multi_speaker_config: å¤šè¯´è¯äººé…ç½®
        tts_provider: TTS æä¾›è€…
        video_processor: è§†é¢‘å¤„ç†å™¨
        audio_repo: éŸ³é¢‘ç‰‡æ®µä»“å‚¨
        cache_repo: ç¼“å­˜ä»“å‚¨
        progress: è¿›åº¦å›è°ƒ

    Returns:
        IncrementalSynthesisResult: åˆæˆç»“æœ
    """
    start_time = time.perf_counter()

    if progress:
        progress(0.0, "å¼€å§‹å¤šè¯´è¯äººè¯­éŸ³å…‹éš†", -1, None)

    # ç»Ÿè®¡å„è¯´è¯äººçš„ç‰‡æ®µæ•°
    speaker_stats = {}
    for idx in range(len(subtitle.segments)):
        speaker_id = multi_speaker_config.get_speaker_for_segment(idx)
        speaker_stats[speaker_id.id] = speaker_stats.get(speaker_id.id, 0) + 1

    print(f"\nğŸ“Š å¤šè¯´è¯äººé…ç½®:")
    print(f"   æ€»ç‰‡æ®µæ•°: {len(subtitle.segments)}")
    print(f"   è¯´è¯äººæ•°: {len(multi_speaker_config.voice_profiles)}")
    for speaker_id, count in speaker_stats.items():
        print(f"   - {speaker_id}: {count} ä¸ªç‰‡æ®µ")

    # æ£€æŸ¥ç¼“å­˜
    cached_segments = {}
    missing_indices = []

    for idx, text_seg in enumerate(subtitle.segments):
        speaker_id = multi_speaker_config.get_speaker_for_segment(idx)

        # å°è¯•åŠ è½½ç¼“å­˜
        audio_seg = audio_repo.load_segment(idx, video.path, text_seg)

        # éªŒè¯ç¼“å­˜çš„è¯´è¯äººæ˜¯å¦åŒ¹é…
        if audio_seg:
            expected_cache_key = _get_segment_cache_key_multi(
                video.path, idx, text_seg.text, speaker_id.id
            )
            if audio_seg.cache_key == expected_cache_key:
                cached_segments[idx] = audio_seg
            else:
                missing_indices.append(idx)
        else:
            missing_indices.append(idx)

    print(f"  ğŸ’¾ ç¼“å­˜å‘½ä¸­: {len(cached_segments)}/{len(subtitle.segments)}")

    # åˆæˆç¼ºå¤±ç‰‡æ®µ
    all_segments = dict(cached_segments)

    if missing_indices:
        print(f"  ğŸ¤ éœ€è¦åˆæˆ {len(missing_indices)} ä¸ªç‰‡æ®µ")

        for i, idx in enumerate(missing_indices):
            text_seg = subtitle.segments[idx]
            speaker_id = multi_speaker_config.get_speaker_for_segment(idx)
            voice_profile = multi_speaker_config.get_voice_profile(speaker_id)

            if progress:
                ratio = i / len(missing_indices)
                progress(
                    ratio,
                    f"åˆæˆç‰‡æ®µ {idx + 1}/{len(subtitle.segments)} [è¯´è¯äºº: {speaker_id.name}]",
                    idx,
                    None
                )

            # åˆæˆ
            audio_seg = _synthesize_segment_with_speaker(
                text_seg=text_seg,
                segment_index=idx,
                voice_profile=voice_profile,
                tts_provider=tts_provider,
                video=video,
                audio_repo=audio_repo
            )

            all_segments[idx] = audio_seg

            if progress:
                progress(
                    (i + 1) / len(missing_indices),
                    f"å®Œæˆç‰‡æ®µ {idx + 1} [è¯´è¯äºº: {speaker_id.name}]",
                    idx,
                    audio_seg
                )

            print(f"  âœ… ç‰‡æ®µ {idx} å·²åˆæˆ [è¯´è¯äºº: {speaker_id.name}]")

    synthesis_time = time.perf_counter() - start_time

    if progress:
        progress(1.0, "å¤šè¯´è¯äººåˆæˆå®Œæˆ", -1, None)

    return IncrementalSynthesisResult(
        total_segments=len(subtitle.segments),
        cached_segments=len(cached_segments),
        regenerated_segments=len(missing_indices),
        audio_segments=tuple(
            all_segments[i] for i in sorted(all_segments.keys())
        ),
        synthesis_time=synthesis_time
    )