from application import *

# å¯¼å…¥é¢†åŸŸå±‚
from domain.entities import (
    # Entities
    Video, Subtitle, AudioTrack,  # Value Objects
)

from domain.ports import (
# Ports
    VideoProcessor, SubtitleWriter, )


def synthesize_video_use_case(
        video: Video,
        subtitles: tuple[Subtitle, ...],
        audio_track: Optional[AudioTrack],
        video_processor: VideoProcessor,
        subtitle_writer: SubtitleWriter,
        output_dir: Path,
        formats: tuple[str, ...] = ("srt", "ass"),
        burn_subtitles: bool = False,
        progress: ProgressCallback = None
) -> VideoSynthesisResult:
    """
    åˆæˆè§†é¢‘ç”¨ä¾‹ï¼ˆçº¯å‡½æ•°ï¼‰- ä¿®å¤ç‰ˆ

    æµç¨‹:
    1. å†™å­—å¹•æ–‡ä»¶ï¼ˆä½¿ç”¨æ˜ç¡®çš„å‘½åè§„åˆ™ï¼‰
    2. å¦‚æœæœ‰éŸ³è½¨ï¼Œåˆå¹¶éŸ³è§†é¢‘
    3. å¦‚æœéœ€è¦ï¼Œçƒ§å½•å­—å¹•
    """
    import time
    start_time = time.time()

    if progress:
        progress(0.0, "å¼€å§‹è§†é¢‘åˆæˆ")

    output_paths = []

    # 1. å†™å­—å¹•æ–‡ä»¶ - ä½¿ç”¨æ˜ç¡®çš„å‘½åè§„åˆ™
    if progress:
        progress(0.2, "ç”Ÿæˆå­—å¹•æ–‡ä»¶")

    # æ ¹æ®è¯­è¨€ä»£ç åˆ¤æ–­å­—å¹•ç±»å‹
    # æ–°è§„èŒƒ: å§‹ç»ˆç”Ÿæˆ zh, en, zh_en ä¸‰ç§å­—å¹•
    base_name = video.path.stem

    for subtitle in subtitles:
        lang_code = subtitle.language.value

        # æ£€æŸ¥æ˜¯å¦æ˜¯åŒè¯­å­—å¹•ï¼ˆæ–‡æœ¬ä¸­åŒ…å«æ¢è¡Œç¬¦ï¼‰
        is_bilingual = any('\n' in seg.text for seg in subtitle.segments)

        if is_bilingual:
            # åŒè¯­å­—å¹•ï¼šå‘½åä¸º zh_en
            file_prefix = "zh_en"
        else:
            # å•è¯­å­—å¹•ï¼šç›´æ¥ä½¿ç”¨è¯­è¨€ä»£ç 
            file_prefix = lang_code

        if "srt" in formats:
            srt_path = output_dir / f"{base_name}.{file_prefix}.srt"
            subtitle_writer.write_srt(subtitle, srt_path)
            output_paths.append(srt_path)
            print(f"ğŸ“ ç”Ÿæˆå­—å¹•: {srt_path.name}")

        if "ass" in formats:
            ass_path = output_dir / f"{base_name}.{file_prefix}.ass"
            subtitle_writer.write_ass(subtitle, ass_path)
            output_paths.append(ass_path)
            print(f"ğŸ“ ç”Ÿæˆå­—å¹•: {ass_path.name}")

    # 2. åˆå¹¶éŸ³è§†é¢‘ï¼ˆå¦‚æœæœ‰é…éŸ³ï¼‰
    if audio_track is not None:
        if progress:
            progress(0.5, "åˆå¹¶éŸ³é¢‘å’Œè§†é¢‘")

        voiced_output = output_dir / f"{video.path.stem}_voiced.mp4"
        video_processor.merge_audio_video(
            video,
            audio_track,
            voiced_output
        )
        output_paths.append(voiced_output)
        print(f"ğŸ¤ ç”Ÿæˆé…éŸ³è§†é¢‘: {voiced_output.name}")

        # ä¸ºé…éŸ³è§†é¢‘çƒ§å½•åŒè¯­å­—å¹•ï¼ˆå¦‚æœæœ‰åŒè¯­å­—å¹•ï¼‰
        if burn_subtitles and len(subtitles) >= 3:
            if progress:
                progress(0.7, "ä¸ºé…éŸ³è§†é¢‘çƒ§å½•åŒè¯­å­—å¹•")

            bilingual_subtitle = subtitles[2]  # ç¬¬ä¸‰ä¸ªæ˜¯åŒè¯­å­—å¹•
            voiced_subtitled = output_dir / f"{video.path.stem}_voiced_subtitled.mp4"
            video_processor.burn_subtitles(
                voiced_output,  # åŸºäºé…éŸ³è§†é¢‘
                bilingual_subtitle,
                voiced_subtitled
            )
            output_paths.append(voiced_subtitled)
            print(f"ğŸ¬ ç”Ÿæˆé…éŸ³+åŒè¯­å­—å¹•è§†é¢‘: {voiced_subtitled.name}")

    # 3. çƒ§å½•å­—å¹•åˆ°åŸå§‹è§†é¢‘ï¼ˆä»…ä¸­æ–‡å­—å¹•ï¼‰
    if burn_subtitles and subtitles:
        if progress:
            progress(0.8, "çƒ§å½•å­—å¹•åˆ°åŸå§‹è§†é¢‘")

        burned_output = output_dir / f"{video.path.stem}_subtitled.mp4"
        video_processor.burn_subtitles(
            video,
            subtitles[0],  # ä½¿ç”¨ä¸­æ–‡å­—å¹•
            burned_output
        )
        output_paths.append(burned_output)
        print(f"ğŸ¬ ç”Ÿæˆç¡¬å­—å¹•è§†é¢‘ï¼ˆä¸­æ–‡ï¼‰: {burned_output.name}")

    if progress:
        progress(1.0, "è§†é¢‘åˆæˆå®Œæˆ")

    processing_time = time.time() - start_time

    return VideoSynthesisResult(
        output_paths=tuple(output_paths),
        processing_time=processing_time
    )
