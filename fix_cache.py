#!/usr/bin/env python
"""
ç¼“å­˜ä¿®å¤è„šæœ¬

ä½¿ç”¨æ–¹æ³•:
    python fix_cache.py              # æ‰«æå¹¶æ˜¾ç¤ºç»Ÿè®¡
    python fix_cache.py --clean      # æ¸…ç†æ— æ•ˆç¼“å­˜
    python fix_cache.py --clean-all  # æ¸…ç†æ‰€æœ‰ç¼“å­˜
"""

import sys
import json
from pathlib import Path


def validate_audio_cache(cached):
    """éªŒè¯éŸ³é¢‘ç¼“å­˜"""
    if cached is None:
        return False

    required = ["audio_samples", "sample_rate", "reference_audio", "reference_duration"]
    if not all(key in cached for key in required):
        return False

    if not isinstance(cached["audio_samples"], (list, tuple)):
        return False

    if len(cached["audio_samples"]) == 0:
        return False

    if not isinstance(cached["sample_rate"], int) or cached["sample_rate"] <= 0:
        return False

    return True


def validate_subtitle_cache(cached):
    """éªŒè¯å­—å¹•ç¼“å­˜"""
    if cached is None:
        return False

    required = ["detected_language", "zh_segments", "en_segments"]
    if not all(key in cached for key in required):
        return False

    if not isinstance(cached["zh_segments"], list) or len(cached["zh_segments"]) == 0:
        return False

    if not isinstance(cached["en_segments"], list) or len(cached["en_segments"]) == 0:
        return False

    # æ£€æŸ¥ç¬¬ä¸€ä¸ª segment çš„ç»“æ„
    for seg in cached["zh_segments"][:1]:
        if not all(key in seg for key in ["text", "start", "end"]):
            return False

    return True


def scan_cache_dir(cache_dir: Path):
    """æ‰«æç¼“å­˜ç›®å½•"""
    stats = {
        "total": 0,
        "valid_audio": 0,
        "valid_subtitle": 0,
        "invalid": 0,
        "corrupt": 0,
        "total_size_mb": 0.0
    }

    invalid_files = []

    if not cache_dir.exists():
        print(f"âŒ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
        return stats, invalid_files

    cache_files = list(cache_dir.glob("*.json"))
    stats["total"] = len(cache_files)

    print(f"\nğŸ” æ‰«æç¼“å­˜ç›®å½•: {cache_dir}")
    print(f"   å‘ç° {len(cache_files)} ä¸ªç¼“å­˜æ–‡ä»¶\n")

    for cache_file in cache_files:
        try:
            # ç»Ÿè®¡å¤§å°
            file_size = cache_file.stat().st_size / (1024 * 1024)
            stats["total_size_mb"] += file_size

            # è¯»å–å¹¶éªŒè¯
            with open(cache_file, 'r', encoding='utf-8') as f:
                cached = json.load(f)

            # åˆ¤æ–­ç±»å‹å¹¶éªŒè¯
            if "audio_samples" in cached:
                if validate_audio_cache(cached):
                    stats["valid_audio"] += 1
                    print(f"  âœ… éŸ³é¢‘: {cache_file.name} ({file_size:.2f} MB)")
                else:
                    stats["invalid"] += 1
                    invalid_files.append(cache_file)
                    print(f"  âŒ éŸ³é¢‘æŸå: {cache_file.name}")
            elif "zh_segments" in cached:
                if validate_subtitle_cache(cached):
                    stats["valid_subtitle"] += 1
                    print(f"  âœ… å­—å¹•: {cache_file.name} ({file_size:.2f} MB)")
                else:
                    stats["invalid"] += 1
                    invalid_files.append(cache_file)
                    print(f"  âŒ å­—å¹•æŸå: {cache_file.name}")
            else:
                stats["invalid"] += 1
                invalid_files.append(cache_file)
                print(f"  â“ æœªçŸ¥ç±»å‹: {cache_file.name}")

        except json.JSONDecodeError:
            stats["corrupt"] += 1
            invalid_files.append(cache_file)
            print(f"  ğŸ’¥ JSON æŸå: {cache_file.name}")
        except Exception as e:
            stats["corrupt"] += 1
            invalid_files.append(cache_file)
            print(f"  âŒ è¯»å–å¤±è´¥: {cache_file.name} - {e}")

    return stats, invalid_files


def print_stats(stats):
    """æ‰“å°ç»Ÿè®¡ä¿¡æ¯"""
    print(f"\n{'=' * 60}")
    print(f"ğŸ“Š ç¼“å­˜ç»Ÿè®¡")
    print(f"{'=' * 60}")
    print(f"  æ€»æ–‡ä»¶æ•°:    {stats['total']}")
    print(f"  æœ‰æ•ˆéŸ³é¢‘:    {stats['valid_audio']}")
    print(f"  æœ‰æ•ˆå­—å¹•:    {stats['valid_subtitle']}")
    print(f"  æ— æ•ˆæ–‡ä»¶:    {stats['invalid']}")
    print(f"  æŸåæ–‡ä»¶:    {stats['corrupt']}")
    print(f"  æ€»å¤§å°:      {stats['total_size_mb']:.2f} MB")
    print(f"{'=' * 60}\n")

    if stats['invalid'] > 0 or stats['corrupt'] > 0:
        print(f"âš ï¸  å‘ç° {stats['invalid'] + stats['corrupt']} ä¸ªé—®é¢˜æ–‡ä»¶")
        print(f"   è¿è¡Œ 'python fix_cache.py --clean' æ¸…ç†")


def clean_invalid_files(invalid_files):
    """æ¸…ç†æ— æ•ˆæ–‡ä»¶"""
    if not invalid_files:
        print("âœ… æ²¡æœ‰éœ€è¦æ¸…ç†çš„æ–‡ä»¶")
        return 0

    print(f"\nğŸ—‘ï¸  å¼€å§‹æ¸…ç† {len(invalid_files)} ä¸ªæ— æ•ˆæ–‡ä»¶...")

    cleaned = 0
    for cache_file in invalid_files:
        try:
            cache_file.unlink()
            cleaned += 1
            print(f"  âœ… å·²åˆ é™¤: {cache_file.name}")
        except Exception as e:
            print(f"  âŒ åˆ é™¤å¤±è´¥: {cache_file.name} - {e}")

    print(f"\nâœ… æ¸…ç†å®Œæˆ: åˆ é™¤äº† {cleaned}/{len(invalid_files)} ä¸ªæ–‡ä»¶")
    return cleaned


def clean_all_cache(cache_dir: Path):
    """æ¸…ç†æ‰€æœ‰ç¼“å­˜"""
    if not cache_dir.exists():
        print(f"âŒ ç¼“å­˜ç›®å½•ä¸å­˜åœ¨: {cache_dir}")
        return 0

    cache_files = list(cache_dir.glob("*.json"))

    if not cache_files:
        print("âœ… ç¼“å­˜ç›®å½•å·²ç»æ˜¯ç©ºçš„")
        return 0

    print(f"\nâš ï¸  ç¡®è®¤è¦åˆ é™¤æ‰€æœ‰ {len(cache_files)} ä¸ªç¼“å­˜æ–‡ä»¶å—ï¼Ÿ")
    print("   è¿™å°†å¯¼è‡´ä¸‹æ¬¡å¤„ç†éœ€è¦é‡æ–°ç”Ÿæˆæ‰€æœ‰ç¼“å­˜")
    confirm = input("   è¾“å…¥ 'yes' ç¡®è®¤: ")

    if confirm.lower() != 'yes':
        print("âŒ å·²å–æ¶ˆ")
        return 0

    print(f"\nğŸ—‘ï¸  å¼€å§‹æ¸…ç†æ‰€æœ‰ç¼“å­˜...")

    cleaned = 0
    for cache_file in cache_files:
        try:
            cache_file.unlink()
            cleaned += 1
        except Exception as e:
            print(f"  âŒ åˆ é™¤å¤±è´¥: {cache_file.name} - {e}")

    print(f"\nâœ… æ¸…ç†å®Œæˆ: åˆ é™¤äº† {cleaned}/{len(cache_files)} ä¸ªæ–‡ä»¶")
    return cleaned


def main():
    """ä¸»å‡½æ•°"""
    # é»˜è®¤ç¼“å­˜ç›®å½•
    cache_dir = Path(".cache")

    # è§£æå‘½ä»¤è¡Œå‚æ•°
    if len(sys.argv) > 1:
        if sys.argv[1] == "--clean":
            # æ¸…ç†æ— æ•ˆç¼“å­˜
            stats, invalid_files = scan_cache_dir(cache_dir)
            print_stats(stats)

            if invalid_files:
                clean_invalid_files(invalid_files)

                # å†æ¬¡æ‰«ææ˜¾ç¤ºç»“æœ
                print(f"\n{'=' * 60}")
                print("ğŸ” æ¸…ç†åé‡æ–°æ‰«æ...")
                stats, invalid_files = scan_cache_dir(cache_dir)
                print_stats(stats)

        elif sys.argv[1] == "--clean-all":
            # æ¸…ç†æ‰€æœ‰ç¼“å­˜
            clean_all_cache(cache_dir)

        elif sys.argv[1] == "--help" or sys.argv[1] == "-h":
            print("""
ç¼“å­˜ä¿®å¤è„šæœ¬

ä½¿ç”¨æ–¹æ³•:
    python fix_cache.py              # æ‰«æå¹¶æ˜¾ç¤ºç»Ÿè®¡
    python fix_cache.py --clean      # æ¸…ç†æ— æ•ˆç¼“å­˜
    python fix_cache.py --clean-all  # æ¸…ç†æ‰€æœ‰ç¼“å­˜ï¼ˆéœ€ç¡®è®¤ï¼‰
    python fix_cache.py --help       # æ˜¾ç¤ºå¸®åŠ©
            """)
        else:
            print(f"âŒ æœªçŸ¥å‚æ•°: {sys.argv[1]}")
            print("   è¿è¡Œ 'python fix_cache.py --help' æŸ¥çœ‹å¸®åŠ©")
    else:
        # é»˜è®¤ï¼šåªæ‰«æä¸æ¸…ç†
        stats, invalid_files = scan_cache_dir(cache_dir)
        print_stats(stats)

        if invalid_files:
            print("\nğŸ’¡ æç¤º:")
            print(f"   è¿è¡Œ 'python fix_cache.py --clean' æ¸…ç† {len(invalid_files)} ä¸ªæ— æ•ˆæ–‡ä»¶")


if __name__ == "__main__":
    main()