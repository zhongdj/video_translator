# infrastructure/adapters/tts/indextts_adapter.py
import os
import sys
from pathlib import Path
from typing import Optional, Tuple
import numpy as np
import torch
import torchaudio

from domain.ports import TTSProvider
from domain.entities import VoiceProfile, AudioSample


class IndexTTSAdapter(TTSProvider):
    """IndexTTS2 é€‚é…å™¨ - ä¿®å¤ç‰ˆ"""

    def __init__(self, model_path: Optional[str] = None, device: str = "cuda"):
        self.device = device
        self._model = None

        # è®¾ç½® IndexTTS2 è·¯å¾„
        current_dir = Path(__file__).parent
        self.indextts2_path = current_dir.parent.parent.parent.parent / "indextts2"

        # åŸºç¡€é…ç½®å‚æ•°
        self.temperature = 0.8
        self.top_p = 0.8
        self.speed = 1.0

        print(f"ğŸ” æ£€æµ‹ IndexTTS2 è·¯å¾„:")
        print(f"   IndexTTS2 ä¸»ç›®å½•: {self.indextts2_path}")
        print(f"   ä¸»ç›®å½•å­˜åœ¨: {self.indextts2_path.exists()}")

        # æ£€æŸ¥å…³é”®ç›®å½•
        self.checkpoints_path = self.indextts2_path / "checkpoints"
        print(f"   checkpoints ç›®å½•: {self.checkpoints_path.exists()}")

        if self.checkpoints_path.exists():
            print(f"   checkpoints å†…å®¹: {list(self.checkpoints_path.glob('*'))}")

        self.device = "cuda" if torch.cuda.is_available() else "cpu"
        self.model = None

        # æ·»åŠ WebUIå‚æ•°
        self.gpt_config = {
            'do_sample': True,
            'temperature': 0.8,
            'top_p': 0.8,
            'top_k': 30,
            'num_beams': 3,
            'repetition_penalty': 10,
            'length_penalty': 0,
        }
        self.max_mel_tokens = 1500
        self.split_max_tokens = 120

        # åˆ›å»ºè¾“å‡ºç›®å½•
        self.output_dir = Path("temp_output")
        self.output_dir.mkdir(exist_ok=True)

    def _load_model(self):
        """åŠ è½½ IndexTTS 2.0 æ¨¡å‹"""
        if not self.indextts2_path.exists():
            raise ImportError(f"âŒ IndexTTS2 ç›®å½•ä¸å­˜åœ¨: {self.indextts2_path}")

        if self.model is not None:
            return self.model

        print(f"ğŸ”„ åŠ è½½ IndexTTS 2.0 æ¨¡å‹...")

        try:
            # æ·»åŠ è·¯å¾„åˆ° sys.path
            if str(self.indextts2_path) not in sys.path:
                sys.path.insert(0, str(self.indextts2_path))

            # å°è¯•ä¸åŒçš„å¯¼å…¥æ–¹å¼
            IndexTTS2 = None
            try:
                from indextts.infer_v2 import IndexTTS2
                print("âœ… ä» indextts.infer_v2 å¯¼å…¥ IndexTTS2 æˆåŠŸ")
            except ImportError as e:
                print(f"âŒ ç¬¬ä¸€ç§å¯¼å…¥æ–¹å¼å¤±è´¥: {e}")
                try:
                    from infer_v2 import IndexTTS2
                    print("âœ… ä» infer_v2 å¯¼å…¥ IndexTTS2 æˆåŠŸ")
                except ImportError as e:
                    print(f"âŒ ç¬¬äºŒç§å¯¼å…¥æ–¹å¼å¤±è´¥: {e}")
                    try:
                        sys.path.append(str(self.indextts2_path))
                        from indextts2.infer_v2 import IndexTTS2
                        print("âœ… ä» indextts2.infer_v2 å¯¼å…¥ IndexTTS2 æˆåŠŸ")
                    except ImportError as e:
                        print(f"âŒ æ‰€æœ‰å¯¼å…¥æ–¹å¼éƒ½å¤±è´¥: {e}")
                        return self._create_dummy_model()

            # åˆå§‹åŒ–æ¨¡å‹
            config_path = self.checkpoints_path / "config.yaml"
            if not config_path.exists():
                # å°è¯•å¯»æ‰¾å…¶ä»–é…ç½®æ–‡ä»¶
                config_files = list(self.checkpoints_path.glob("*.yaml")) + list(self.checkpoints_path.glob("*.yml"))
                if config_files:
                    config_path = config_files[0]
                    print(f"ğŸ”§ ä½¿ç”¨å¤‡ç”¨é…ç½®æ–‡ä»¶: {config_path}")
                else:
                    raise FileNotFoundError(f"æ²¡æœ‰æ‰¾åˆ°é…ç½®æ–‡ä»¶ in {self.checkpoints_path}")

            print(f"ğŸ”§ ä½¿ç”¨é…ç½®æ–‡ä»¶: {config_path}")
            print(f"ğŸ”§ æ¨¡å‹ç›®å½•: {self.checkpoints_path}")

            self.model = IndexTTS2(
                model_dir=str(self.checkpoints_path),
                cfg_path=str(config_path),
                device=self.device,
                use_fp16=(self.device != "cpu")
            )

            print("âœ… IndexTTS 2.0 æ¨¡å‹åŠ è½½å®Œæˆ")
            return self.model

        except Exception as e:
            print(f"âŒ æ¨¡å‹åˆå§‹åŒ–å¤±è´¥: {e}")
            return self._create_dummy_model()

    def _create_dummy_model(self):
        """åˆ›å»ºè™šæ‹Ÿæ¨¡å‹ç”¨äºæµ‹è¯•"""

        class DummyModel:
            def infer(self, text, reference_audio, speed=1.0):
                print(f"ğŸ”Š è™šæ‹Ÿåˆæˆ: '{text}' (å‚è€ƒéŸ³é¢‘: {reference_audio}, è¯­é€Ÿ: {speed})")
                # ç”ŸæˆåŸºäºæ–‡æœ¬é•¿åº¦çš„æµ‹è¯•éŸ³é¢‘
                duration = max(1.0, len(text) * 0.1)
                samples = int(duration * 22050)
                t = np.linspace(0, duration * 2 * np.pi, samples)
                audio_data = 0.3 * np.sin(440 * t) * np.exp(-0.001 * t)
                return (audio_data, 22050)  # è¿”å›å…ƒç»„

        return DummyModel()

    def _handle_model_output(self, result, output_path: Path) -> Tuple[np.ndarray, int]:
        """å¤„ç†æ¨¡å‹è¾“å‡ºï¼Œé€‚åº”ä¸åŒçš„è¿”å›ç±»å‹"""
        print(f"ğŸ”§ å¤„ç†æ¨¡å‹è¾“å‡ºï¼Œç±»å‹: {type(result)}")

        # å¦‚æœè¿”å›çš„æ˜¯è·¯å¾„ï¼Œè¯»å–éŸ³é¢‘æ–‡ä»¶
        if isinstance(result, (str, Path)):
            audio_path = Path(result)
            if audio_path.exists():
                print(f"ğŸ“ ä»æ–‡ä»¶è¯»å–éŸ³é¢‘: {audio_path}")
                audio_data, sample_rate = torchaudio.load(audio_path)
                audio_data = audio_data.numpy()[0]  # è½¬æ¢ä¸ºnumpyå¹¶å–ç¬¬ä¸€ä¸ªé€šé“
                return audio_data, sample_rate
            else:
                raise FileNotFoundError(f"éŸ³é¢‘æ–‡ä»¶ä¸å­˜åœ¨: {audio_path}")

        # å¦‚æœè¿”å›çš„æ˜¯å…ƒç»„ (audio_data, sample_rate)
        elif isinstance(result, tuple) and len(result) == 2:
            audio_data, sample_rate = result

            # å¤„ç†torch tensor
            if torch.is_tensor(audio_data):
                audio_data = audio_data.cpu().numpy()

            # ç¡®ä¿æ˜¯å•å£°é“
            if audio_data.ndim > 1:
                audio_data = audio_data[0]  # å–ç¬¬ä¸€ä¸ªé€šé“

            return audio_data, sample_rate

        # å¦‚æœè¿”å›çš„æ˜¯å•ä¸ªå€¼ï¼ˆå¯èƒ½æ˜¯éŸ³é¢‘æ•°æ®ï¼‰ï¼Œå‡è®¾é‡‡æ ·ç‡ä¸º22050
        else:
            print(f"âš ï¸ æœªçŸ¥è¿”å›ç±»å‹ï¼Œå°è¯•å¤„ç†...")
            audio_data = result
            if torch.is_tensor(audio_data):
                audio_data = audio_data.cpu().numpy()

            if audio_data.ndim > 1:
                audio_data = audio_data[0]

            return audio_data, 22050

    def synthesize(
            self,
            text: str,
            voice_profile: VoiceProfile,
            target_duration: Optional[float] = None
    ) -> AudioSample:
        """å®ç° TTSProvider æ¥å£"""
        if self.model is None:
            self.model = self._load_model()

        print(f"ğŸ¯ å¼€å§‹è¯­éŸ³åˆæˆ...")
        print(f"   å‚è€ƒéŸ³é¢‘: {voice_profile.reference_audio_path}")
        print(f"   ç”Ÿæˆæ–‡æœ¬: {text}")

        try:
            # å‡†å¤‡è¾“å‡ºè·¯å¾„
            import time
            output_path = self.output_dir / f"tts_output_{int(time.time())}_{hash(text) % 100000}.wav"

            # è°ƒç”¨ IndexTTS2 åˆæˆ
            if hasattr(self.model, 'infer_with_config'):
                print("ğŸ”§ ä½¿ç”¨ infer_with_config æ–¹æ³•")
                result = self.model.infer_with_config(
                    spk_audio_prompt=str(voice_profile.reference_audio_path),
                    text=text,
                    output_path=str(output_path),
                    emotion_prompt=None,
                    do_sample=self.gpt_config['do_sample'],
                    temperature=self.gpt_config['temperature'],
                    top_p=self.gpt_config['top_p'],
                    top_k=self.gpt_config['top_k'],
                    num_beams=self.gpt_config['num_beams'],
                    repetition_penalty=self.gpt_config['repetition_penalty'],
                    length_penalty=self.gpt_config['length_penalty'],
                    max_mel_tokens=self.max_mel_tokens
                )
            else:
                print("ğŸ”§ ä½¿ç”¨ infer æ–¹æ³•")
                result = self.model.infer(
                    spk_audio_prompt=str(voice_profile.reference_audio_path),
                    text=text,
                    output_path=str(output_path),
                    verbose=True
                )

            # å¤„ç†æ¨¡å‹è¾“å‡º
            audio_data, sample_rate = self._handle_model_output(result, output_path)

            print(f"âœ… æˆåŠŸç”ŸæˆéŸ³é¢‘: {len(audio_data)}é‡‡æ ·ç‚¹, {sample_rate}Hzé‡‡æ ·ç‡")

            # è®¡ç®—æ—¶é•¿
            duration = len(audio_data) / sample_rate
            print(f"â±ï¸ éŸ³é¢‘æ—¶é•¿: {duration:.2f}ç§’")

            # æ£€æŸ¥éŸ³é¢‘æ•°æ®
            if audio_data.size == 0:
                raise ValueError("ç”Ÿæˆçš„éŸ³é¢‘æ•°æ®ä¸ºç©º")

            print(f"ğŸ“Š éŸ³é¢‘æ•°æ®èŒƒå›´: [{np.min(audio_data):.4f}, {np.max(audio_data):.4f}]")

            # è½¬æ¢ä¸º tuple ä»¥ç¬¦åˆ AudioSample çš„è¦æ±‚
            audio_tuple = tuple(audio_data.tolist())
            print(f"ğŸ”„ è½¬æ¢éŸ³é¢‘æ•°æ®: ndarray -> tuple (é•¿åº¦: {len(audio_tuple)})")

            return AudioSample(
                samples=audio_tuple,
                sample_rate=sample_rate
            )

        except Exception as e:
            print(f"âŒ è¯­éŸ³åˆæˆå¤±è´¥: {e}")
            import traceback
            traceback.print_exc()

            # è¿”å›é™éŸ³ä½œä¸ºé™çº§æ–¹æ¡ˆ
            silent_samples = int(22050 * 2.0)  # 2ç§’é™éŸ³
            silent_audio = tuple(np.zeros(silent_samples).tolist())
            return AudioSample(
                samples=silent_audio,
                sample_rate=22050
            )

    def update_config(self, temperature: float = None, top_p: float = None, speed: float = None):
        """æ›´æ–°é…ç½®å‚æ•°"""
        if temperature is not None:
            self.temperature = temperature
            self.gpt_config['temperature'] = temperature
        if top_p is not None:
            self.top_p = top_p
            self.gpt_config['top_p'] = top_p
        if speed is not None:
            self.speed = speed

    def unload(self):
        """å¸è½½æ¨¡å‹"""
        if self.model is not None:
            del self.model
            self.model = None
            if torch.cuda.is_available():
                torch.cuda.empty_cache()
            print("ğŸ§¹ IndexTTS2 æ¨¡å‹å·²å¸è½½")